{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a14239",
   "metadata": {},
   "source": [
    "## Get ensembl id of essential lncRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df289b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped IDs -> mapped_ensembl_ids_human.csv\n",
      "unmatched -> unmatched_genes_human.csv\n",
      "\n",
      "Match summary:\n",
      "match_type\n",
      "name      29550\n",
      "direct    11409\n",
      "<NA>       6469\n",
      "coord      6403\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Human\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Use Ensembl BED directory\n",
    "ensembl_dir = f\"../../reference_lncRNA/human/bed/ensembl/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BED utilities: extract version number and sort by version\n",
    "# ------------------------------------------------------------\n",
    "def extract_version(filename: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract Ensembl version number from BED filename,\n",
    "    \"\"\"\n",
    "    m = re.search(r'GRCh38\\.(\\d+)\\.bed$', filename)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def list_bed_files_sorted(bed_dir: str):\n",
    "    \"\"\"\n",
    "    List all BED files in directory and sort them by version\n",
    "    in descending order (newer versions first)\n",
    "    \"\"\"\n",
    "    bed_files = [f for f in os.listdir(bed_dir) if f.endswith(\".bed\")]\n",
    "    return sorted(bed_files, key=extract_version, reverse=True)\n",
    "\n",
    "def read_ensembl_bed(bed_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read Ensembl BED file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(bed_path, sep=\"\\t\", header=None, comment=\"#\", dtype={0: str})\n",
    "    if df.shape[1] < 6:\n",
    "        raise ValueError(f\"{bed_path} has fewer than 6 columns\")\n",
    "\n",
    "    df = df.iloc[:, :6].copy()\n",
    "    df.columns = [\"chr\", \"bed_start\", \"bed_end\", \"gene_name\", \"ensembl_id\", \"bed_strand\"]\n",
    "\n",
    "    df[\"bed_start\"] = pd.to_numeric(df[\"bed_start\"], errors=\"coerce\")\n",
    "    df[\"bed_end\"] = pd.to_numeric(df[\"bed_end\"], errors=\"coerce\")\n",
    "\n",
    "    return df.dropna(subset=[\"chr\", \"bed_start\", \"bed_end\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Mapping function\n",
    "# ------------------------------------------------------------\n",
    "def map_geneid_from_beds(need_df, bed_dir):\n",
    "    out = need_df.copy()\n",
    "    out[\"ensembl_id\"] = pd.NA  # final ensembl id\n",
    "    out[\"match_type\"] = pd.NA  # direct/name/coord\n",
    "\n",
    "    bed_files = list_bed_files_sorted(bed_dir)\n",
    "\n",
    "    # ============================================================\n",
    "    # First pass: if gene_id is already ENSG -> directly assign\n",
    "    # ============================================================\n",
    "    mask_direct = out[\"gene_id\"].notna() & out[\"gene_id\"].astype(str).str.startswith(\"ENSG\")\n",
    "    out.loc[mask_direct, \"ensembl_id\"] = out.loc[mask_direct, \"gene_id\"]\n",
    "    out.loc[mask_direct, \"match_type\"] = \"direct\"\n",
    "\n",
    "    # ============================================================\n",
    "    # Second pass: gene_name matching\n",
    "    # ============================================================\n",
    "    for bed_file in bed_files:\n",
    "        if not out[\"ensembl_id\"].isna().any():\n",
    "            break\n",
    "\n",
    "        bed = read_ensembl_bed(os.path.join(bed_dir, bed_file))\n",
    "\n",
    "        name_to_id = (\n",
    "            bed.dropna(subset=[\"gene_name\", \"ensembl_id\"])\n",
    "               .groupby(\"gene_name\", as_index=False)[\"ensembl_id\"]\n",
    "               .first()\n",
    "        )\n",
    "\n",
    "        tmp = out[out[\"ensembl_id\"].isna()][[\"gene_name_single\"]].merge(\n",
    "            name_to_id,\n",
    "            left_on=\"gene_name_single\",\n",
    "            right_on=\"gene_name\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        idxs = out.index[out[\"ensembl_id\"].isna()]\n",
    "        matched = tmp[\"ensembl_id\"].notna()\n",
    "\n",
    "        out.loc[idxs[matched], \"ensembl_id\"] = tmp.loc[matched, \"ensembl_id\"].values\n",
    "        out.loc[idxs[matched], \"match_type\"] = \"name\"\n",
    "\n",
    "    # ============================================================\n",
    "    # Third pass: coordinate overlap matching (only remaining NA)\n",
    "    # Condition:\n",
    "    #   - same chr\n",
    "    #   - same strand\n",
    "    #   - overlap_len / query_len >= 0.5\n",
    "    # ============================================================\n",
    "    for bed_file in bed_files:\n",
    "        if not out[\"ensembl_id\"].isna().any():\n",
    "            break\n",
    "\n",
    "        bed = read_ensembl_bed(os.path.join(bed_dir, bed_file))\n",
    "\n",
    "        # group for faster lookup\n",
    "        bed_by_chr = {c: g for c, g in bed.groupby(\"chr\", sort=False)}\n",
    "\n",
    "        for idx in out.index[out[\"ensembl_id\"].isna()]:\n",
    "            r = out.loc[idx]\n",
    "            chr_ = r[\"chr\"]\n",
    "            strand = r[\"strand\"]\n",
    "\n",
    "            if chr_ not in bed_by_chr:\n",
    "                continue\n",
    "            if strand not in {\"+\", \"-\"}:\n",
    "                continue\n",
    "\n",
    "            query_start = int(r[\"start\"])\n",
    "            query_end = int(r[\"end\"])\n",
    "            query_len = query_end - query_start\n",
    "            if query_len <= 0:\n",
    "                continue\n",
    "\n",
    "            g = bed_by_chr[chr_]\n",
    "            g = g[g[\"bed_strand\"] == strand]\n",
    "\n",
    "            # Find overlapping genes\n",
    "            overlaps = g[(g[\"bed_start\"] < query_end) & (g[\"bed_end\"] > query_start)]\n",
    "            if overlaps.empty:\n",
    "                continue\n",
    "\n",
    "            # Compute overlap length\n",
    "            overlaps = overlaps.copy()\n",
    "            overlaps[\"overlap_len\"] = overlaps.apply(\n",
    "                lambda x: min(query_end, x[\"bed_end\"]) - max(query_start, x[\"bed_start\"]),\n",
    "                axis=1\n",
    "            )\n",
    "            overlaps = overlaps[overlaps[\"overlap_len\"] > 0]\n",
    "\n",
    "            if overlaps.empty:\n",
    "                continue\n",
    "\n",
    "            # overlap ratio based on query length (unmapped gene)\n",
    "            overlaps[\"overlap_ratio\"] = overlaps[\"overlap_len\"] / query_len\n",
    "\n",
    "            # keep only >= 1\n",
    "            overlaps = overlaps[overlaps[\"overlap_ratio\"] >= 1]\n",
    "            if overlaps.empty:\n",
    "                continue\n",
    "\n",
    "            # Choose best hit:\n",
    "            #  1) max overlap_ratio\n",
    "            #  2) if tie -> shortest Ensembl gene span\n",
    "            overlaps[\"span\"] = overlaps[\"bed_end\"] - overlaps[\"bed_start\"]\n",
    "            best = overlaps.sort_values([\"overlap_ratio\", \"span\"], ascending=[False, True]).iloc[0]\n",
    "\n",
    "            out.at[idx, \"ensembl_id\"] = best[\"ensembl_id\"]\n",
    "            out.at[idx, \"match_type\"] = \"coord\"\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main\n",
    "# ------------------------------------------------------------\n",
    "all_lnc = pd.read_csv(f\"../../data/LPI/human/lncRNA.csv\")\n",
    "\n",
    "# Remove invalid gene_name entries\n",
    "all_lnc = all_lnc[\n",
    "    (all_lnc[\"gene_name\"].notna()) &\n",
    "    (all_lnc[\"gene_name\"] != \"-\") &\n",
    "    (all_lnc[\"gene_name\"] != \"\")\n",
    "]\n",
    "\n",
    "# Split multiple gene names\n",
    "all_lnc[\"gene_name_single\"] = all_lnc[\"gene_name\"].astype(str).str.split(\";\")\n",
    "need = all_lnc.explode(\"gene_name_single\", ignore_index=True)\n",
    "\n",
    "need[\"gene_name_single\"] = need[\"gene_name_single\"].astype(str).str.strip()\n",
    "need = need[need[\"gene_name_single\"] != \"\"]\n",
    "\n",
    "# Load BED coordinates\n",
    "lnc_bed = pd.read_csv(f\"../../process/construct_lppi/human_lncRNA_0-based.bed\", sep=\"\\t\", header=None)\n",
    "lnc_bed.columns = [\"chr\", \"start\", \"end\", \"identifier\", \"score\", \"strand\"]\n",
    "lnc_bed = lnc_bed[[\"chr\", \"start\", \"end\", \"identifier\", \"strand\"]]\n",
    "\n",
    "need = need.merge(lnc_bed, on=\"identifier\", how=\"inner\")\n",
    "\n",
    "need = need[[\"identifier\", \"gene_name_single\", \"gene_id\", \"chr\", \"start\", \"end\", \"strand\"]].copy()\n",
    "mapped = map_geneid_from_beds(need, ensembl_dir)\n",
    "\n",
    "# Output mapped Ensembl IDs\n",
    "out_ids = f\"mapped_ensembl_ids_human.csv\"\n",
    "mapped.dropna(subset=[\"ensembl_id\"])[[\"identifier\", \"ensembl_id\"]].drop_duplicates().sort_values(\n",
    "    by=[\"identifier\", \"ensembl_id\"]\n",
    ").to_csv(out_ids, index=False)\n",
    "\n",
    "# Output unmatched genes\n",
    "out_unmatched = f\"unmatched_genes_human.csv\"\n",
    "mapped[mapped[\"ensembl_id\"].isna()][\n",
    "    [\"identifier\", \"gene_name_single\", \"gene_id\", \"chr\", \"start\", \"end\", \"strand\"]\n",
    "].drop_duplicates().to_csv(out_unmatched, index=False)\n",
    "\n",
    "print(f\"mapped IDs -> {out_ids}\")\n",
    "print(f\"unmatched -> {out_unmatched}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ffc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped IDs -> mapped_ensembl_ids_mouse.csv\n",
      "unmatched -> unmatched_genes_mouse.csv\n",
      "\n",
      "Match summary:\n",
      "match_type\n",
      "coord     14041\n",
      "name       9121\n",
      "<NA>       7858\n",
      "direct     7164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mouse\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Use Ensembl BED directory\n",
    "ensembl_dir = f\"../../reference_lncRNA/mouse/bed/ensembl/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BED utilities: extract version number and sort by version\n",
    "# ------------------------------------------------------------\n",
    "def extract_version(filename: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract Ensembl version number from BED filename.\n",
    "    \"\"\"\n",
    "    m = re.search(r'GRCm38\\.(\\d+)\\.bed$', filename)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def list_bed_files_sorted(bed_dir: str):\n",
    "    \"\"\"\n",
    "    List only GRCm38 BED files and sort by version (desc).\n",
    "    \"\"\"\n",
    "    bed_files = [\n",
    "        f for f in os.listdir(bed_dir)\n",
    "        if re.match(r\"Mus_musculus\\.GRCm38\\.\\d+\\.bed$\", f)\n",
    "    ]\n",
    "    return sorted(bed_files, key=extract_version, reverse=True)\n",
    "\n",
    "def read_ensembl_bed(bed_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read Ensembl BED file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(bed_path, sep=\"\\t\", header=None, comment=\"#\", dtype={0: str})\n",
    "    if df.shape[1] < 6:\n",
    "        raise ValueError(f\"{bed_path} has fewer than 6 columns\")\n",
    "\n",
    "    df = df.iloc[:, :6].copy()\n",
    "    df.columns = [\"chr\", \"bed_start\", \"bed_end\", \"gene_name\", \"ensembl_id\", \"bed_strand\"]\n",
    "\n",
    "    df[\"bed_start\"] = pd.to_numeric(df[\"bed_start\"], errors=\"coerce\")\n",
    "    df[\"bed_end\"] = pd.to_numeric(df[\"bed_end\"], errors=\"coerce\")\n",
    "\n",
    "    return df.dropna(subset=[\"chr\", \"bed_start\", \"bed_end\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Mapping function\n",
    "# ------------------------------------------------------------\n",
    "def map_geneid_from_beds(need_df, bed_dir):\n",
    "    out = need_df.copy()\n",
    "    out[\"ensembl_id\"] = pd.NA\n",
    "    out[\"match_type\"] = pd.NA\n",
    "\n",
    "    bed_files = list_bed_files_sorted(bed_dir)\n",
    "\n",
    "    # ============================================================\n",
    "    # First pass: direct mapping if gene_id is ENSMUSG\n",
    "    # ============================================================\n",
    "    mask_direct = out[\"gene_id\"].notna() & out[\"gene_id\"].astype(str).str.startswith(\"ENSMUSG\")\n",
    "    out.loc[mask_direct, \"ensembl_id\"] = out.loc[mask_direct, \"gene_id\"]\n",
    "    out.loc[mask_direct, \"match_type\"] = \"direct\"\n",
    "\n",
    "    # ============================================================\n",
    "    # Second pass: name matching across BED files\n",
    "    # ============================================================\n",
    "    for bed_file in bed_files:\n",
    "        if not out[\"ensembl_id\"].isna().any():\n",
    "            break\n",
    "\n",
    "        bed = read_ensembl_bed(os.path.join(bed_dir, bed_file))\n",
    "\n",
    "        name_to_id = (\n",
    "            bed.dropna(subset=[\"gene_name\", \"ensembl_id\"])\n",
    "               .groupby(\"gene_name\", as_index=False)[\"ensembl_id\"]\n",
    "               .first()\n",
    "        )\n",
    "\n",
    "        tmp = out[out[\"ensembl_id\"].isna()][[\"gene_name_single\"]].merge(\n",
    "            name_to_id,\n",
    "            left_on=\"gene_name_single\",\n",
    "            right_on=\"gene_name\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        idxs = out.index[out[\"ensembl_id\"].isna()]\n",
    "        matched = tmp[\"ensembl_id\"].notna()\n",
    "\n",
    "        out.loc[idxs[matched], \"ensembl_id\"] = tmp.loc[matched, \"ensembl_id\"].values\n",
    "        out.loc[idxs[matched], \"match_type\"] = \"name\"\n",
    "\n",
    "    # ============================================================\n",
    "    # Third pass: coordinate overlap matching (remaining NA only)\n",
    "    # Condition:\n",
    "    #   - same chr\n",
    "    #   - same strand\n",
    "    #   - overlap_len / query_len >= 0.5\n",
    "    # ============================================================\n",
    "    for bed_file in bed_files:\n",
    "        if not out[\"ensembl_id\"].isna().any():\n",
    "            break\n",
    "\n",
    "        bed = read_ensembl_bed(os.path.join(bed_dir, bed_file))\n",
    "        bed_by_chr = {c: g for c, g in bed.groupby(\"chr\", sort=False)}\n",
    "\n",
    "        for idx in out.index[out[\"ensembl_id\"].isna()]:\n",
    "            r = out.loc[idx]\n",
    "            chr_ = r[\"chr\"]\n",
    "            strand = r[\"strand\"]\n",
    "\n",
    "            if chr_ not in bed_by_chr:\n",
    "                continue\n",
    "            if strand not in {\"+\", \"-\"}:\n",
    "                continue\n",
    "\n",
    "            query_start = int(r[\"start\"])\n",
    "            query_end = int(r[\"end\"])\n",
    "            query_len = query_end - query_start\n",
    "            if query_len <= 0:\n",
    "                continue\n",
    "\n",
    "            g = bed_by_chr[chr_]\n",
    "            g = g[g[\"bed_strand\"] == strand]\n",
    "\n",
    "            overlaps = g[(g[\"bed_start\"] < query_end) & (g[\"bed_end\"] > query_start)]\n",
    "            if overlaps.empty:\n",
    "                continue\n",
    "\n",
    "            overlaps = overlaps.copy()\n",
    "            overlaps[\"overlap_len\"] = overlaps.apply(\n",
    "                lambda x: min(query_end, x[\"bed_end\"]) - max(query_start, x[\"bed_start\"]),\n",
    "                axis=1\n",
    "            )\n",
    "            overlaps = overlaps[overlaps[\"overlap_len\"] > 0]\n",
    "            if overlaps.empty:\n",
    "                continue\n",
    "\n",
    "            overlaps[\"overlap_ratio\"] = overlaps[\"overlap_len\"] / query_len\n",
    "            overlaps = overlaps[overlaps[\"overlap_ratio\"] >= 1]\n",
    "            if overlaps.empty:\n",
    "                continue\n",
    "\n",
    "            overlaps[\"span\"] = overlaps[\"bed_end\"] - overlaps[\"bed_start\"]\n",
    "            best = overlaps.sort_values([\"overlap_ratio\", \"span\"], ascending=[False, True]).iloc[0]\n",
    "\n",
    "            out.at[idx, \"ensembl_id\"] = best[\"ensembl_id\"]\n",
    "            out.at[idx, \"match_type\"] = \"coord\"\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main\n",
    "# ------------------------------------------------------------\n",
    "all_lnc = pd.read_csv(f\"../../data/LPI/mouse/lncRNA.csv\")\n",
    "\n",
    "# Remove invalid gene_name entries\n",
    "all_lnc = all_lnc[\n",
    "    (all_lnc[\"gene_name\"].notna()) &\n",
    "    (all_lnc[\"gene_name\"] != \"-\") &\n",
    "    (all_lnc[\"gene_name\"] != \"\")\n",
    "]\n",
    "\n",
    "# Split multiple gene names\n",
    "all_lnc[\"gene_name_single\"] = all_lnc[\"gene_name\"].astype(str).str.split(\";\")\n",
    "need = all_lnc.explode(\"gene_name_single\", ignore_index=True)\n",
    "\n",
    "need[\"gene_name_single\"] = need[\"gene_name_single\"].astype(str).str.strip()\n",
    "need = need[need[\"gene_name_single\"] != \"\"]\n",
    "\n",
    "# Load BED coordinates for lncRNAs\n",
    "lnc_bed = pd.read_csv(f\"../../process/construct_lppi/mouse_lncRNA_0-based.bed\", sep=\"\\t\", header=None)\n",
    "lnc_bed.columns = [\"chr\", \"start\", \"end\", \"identifier\", \"score\", \"strand\"]\n",
    "lnc_bed = lnc_bed[[\"chr\", \"start\", \"end\", \"identifier\", \"strand\"]]\n",
    "\n",
    "need = need.merge(lnc_bed, on=\"identifier\", how=\"inner\")\n",
    "\n",
    "need = need[[\"identifier\", \"gene_name_single\", \"gene_id\", \"chr\", \"start\", \"end\", \"strand\"]].copy()\n",
    "mapped = map_geneid_from_beds(need, ensembl_dir)\n",
    "\n",
    "# Output mapped Ensembl IDs\n",
    "out_ids = f\"mapped_ensembl_ids_mouse.csv\"\n",
    "mapped.dropna(subset=[\"ensembl_id\"])[[\"identifier\", \"ensembl_id\"]].drop_duplicates().sort_values(\n",
    "    by=[\"identifier\", \"ensembl_id\"]\n",
    ").to_csv(out_ids, index=False)\n",
    "\n",
    "# Output unmatched genes\n",
    "out_unmatched = f\"unmatched_genes_mouse.csv\"\n",
    "mapped[mapped[\"ensembl_id\"].isna()][\n",
    "    [\"identifier\", \"gene_name_single\", \"gene_id\", \"chr\", \"start\", \"end\", \"strand\"]\n",
    "].drop_duplicates().to_csv(out_unmatched, index=False)\n",
    "\n",
    "print(f\"mapped IDs -> {out_ids}\")\n",
    "print(f\"unmatched -> {out_unmatched}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07667818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k = 40\n",
    "species = 'human'\n",
    "\n",
    "lnc_mapping = pd.read_csv(f\"../../data/LPI/{species}/lncRNA_mapping.csv\")\n",
    "ensembl_mapping = pd.read_csv(f\"mapped_ensembl_ids_{species}.csv\")\n",
    "\n",
    "for tissue in ['heart', 'lung', 'stomach', 'common']:\n",
    "    ess_lnc = pd.read_csv(\n",
    "        f\"../ess_number/filtered/{species}/BC_top{k}pct_{species}_{tissue}_esslnc.csv\",\n",
    "        header=None, names=['lncRNA_id']\n",
    "    )\n",
    "\n",
    "    ess_lnc = (\n",
    "        ess_lnc\n",
    "        .merge(lnc_mapping, on='lncRNA_id', how='inner')\n",
    "        .merge(ensembl_mapping, left_on='member_id', right_on='identifier', how='inner')\n",
    "    )\n",
    "\n",
    "    ess_lnc[['ensembl_id']].drop_duplicates().to_csv(\n",
    "        f\"{species}_{tissue}.txt\",\n",
    "        index=False, header=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8651a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k = 60\n",
    "species = 'mouse'\n",
    "\n",
    "lnc_mapping = pd.read_csv(f\"../../data/LPI/{species}/lncRNA_mapping.csv\")\n",
    "ensembl_mapping = pd.read_csv(f\"mapped_ensembl_ids_{species}.csv\")\n",
    "\n",
    "for tissue in ['heart', 'lung', 'brain', 'common']:\n",
    "    ess_lnc = pd.read_csv(\n",
    "        f\"../ess_number/filtered/{species}/BC_top{k}pct_{species}_{tissue}_esslnc.csv\",\n",
    "        header=None, names=['lncRNA_id']\n",
    "    )\n",
    "\n",
    "    ess_lnc = (\n",
    "        ess_lnc\n",
    "        .merge(lnc_mapping, on='lncRNA_id', how='inner')\n",
    "        .merge(ensembl_mapping, left_on='member_id', right_on='identifier', how='inner')\n",
    "    )\n",
    "\n",
    "    ess_lnc[['ensembl_id']].drop_duplicates().to_csv(\n",
    "        f\"{species}_{tissue}.txt\",\n",
    "        index=False, header=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7690a",
   "metadata": {},
   "source": [
    "### Statistic results of  Go Term(BP,CC,MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6505e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = 'mouse'\n",
    "if species == \"mouse\":\n",
    "\titem = ['heart', 'lung', 'brain', 'common']\n",
    "else:\n",
    "\titem = ['heart', 'lung', 'stomach', 'common']\n",
    "\n",
    "# Read the file\n",
    "for i in item:\n",
    "\tfile_path = f'./DAVID_chart/{species}_{i}.csv'  \n",
    "\tdf = pd.read_csv(file_path)  \n",
    "\tdf = df[['Category', 'Term', 'P-Value', 'Fold Enrichment', 'FDR']]\n",
    "\n",
    "\t# Filter out rows with FDR >= 0.05 (non-significant GO terms)\n",
    "\tsignificant_df = df[df['FDR'] < 0.05]\n",
    "\tsignificant_df = significant_df[significant_df['Fold Enrichment'] > 1]\n",
    "\n",
    "\t# For each category, get the top 5 GO terms by sorting based on p-value\n",
    "\ttop_bp = significant_df[significant_df['Category'] == 'GOTERM_BP_DIRECT'].sort_values('P-Value').head(5)\n",
    "\ttop_cc = significant_df[significant_df['Category'] == 'GOTERM_CC_DIRECT'].sort_values('P-Value').head(5)\n",
    "\ttop_mf = significant_df[significant_df['Category'] == 'GOTERM_MF_DIRECT'].sort_values('P-Value').head(5)\n",
    "\tdf_go = pd.concat([top_bp, top_cc, top_mf], ignore_index=True)\n",
    "\tdf_go.to_csv(f\"./filtered_go/{species}_{i}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b8c54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged 8 CSV files into one sheet in go_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    \"./filtered_go/human_heart.csv\",\n",
    "    \"./filtered_go/human_lung.csv\",\n",
    "    \"./filtered_go/human_stomach.csv\",\n",
    "    \"./filtered_go/human_common.csv\",\n",
    "    \"./filtered_go/mouse_heart.csv\",\n",
    "    \"./filtered_go/mouse_lung.csv\",\n",
    "    \"./filtered_go/mouse_brain.csv\",\n",
    "    \"./filtered_go/mouse_common.csv\",\n",
    "]\n",
    "\n",
    "output_excel_file = \"go_data.xlsx\"\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract name like human_heart\n",
    "    base = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "    species, tissue = base.split(\"_\", 1)\n",
    "\n",
    "    # Insert metadata columns\n",
    "    df.insert(0, \"Species\", species)\n",
    "    df.insert(1, \"Tissue\", tissue)\n",
    "\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Concatenate all\n",
    "merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Write to one sheet\n",
    "merged_df.to_excel(output_excel_file, sheet_name=\"GO\", index=False)\n",
    "\n",
    "print(f\"✅ Merged {len(csv_files)} CSV files into one sheet in {output_excel_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
