{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get gene symbol to run DAVID pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tissue specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union of essential gene names saved successfully.\n",
      "Union of essential gene names saved successfully.\n",
      "Union of essential gene names saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = \"mouse\"\n",
    "\n",
    "if species == \"human\":\n",
    "    tissues = ['heart', 'lung', 'stomach']\n",
    "    k = 30\n",
    "else:\n",
    "    tissues = ['heart', 'lung', 'brain']\n",
    "    k = 50\n",
    "\n",
    "all_ess = pd.read_csv(f\"../../results/{species}/{species}_essential_genes_union.csv\")\n",
    "\n",
    "for t in tissues:\n",
    "    # Read the essential gene predictions\n",
    "    prediction_ess = pd.read_csv(f\"../ess_number/filtered/{species}/BC_top{k}pct_{species}_{t}_esslnc.csv\")\n",
    "    prediction_ess.columns = ['lncRNA_id']\n",
    "    p_ess = all_ess[all_ess['lncRNA_id'].isin(prediction_ess['lncRNA_id'])]\n",
    "\n",
    "    # Filter out rows where 'gene_name' is '-'\n",
    "    p_ess = p_ess[p_ess['gene_name'] != '-']\n",
    "\n",
    "    # Apply the process_quoted_strings function to each row in the 'gene_name' column\n",
    "\n",
    "    # Process and explode the 'gene_name' column\n",
    "    ess_name = p_ess['gene_name'].str.split(';').explode().reset_index(drop=True)\n",
    "\n",
    "    # Convert the set to a DataFrame\n",
    "    ess_name_df = pd.DataFrame(list(ess_name), columns=['gene_name'])\n",
    "\n",
    "    # Save the final union of essential gene names to a file\n",
    "    ess_name_df.to_csv(f\"ess_name_{species}_{t}.txt\", index=False, header=None)\n",
    "\n",
    "    print(\"Union of essential gene names saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union of essential gene names saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = \"human\"\n",
    "\n",
    "all_ess = pd.read_csv(f\"../../results/{species}/{species}_essential_genes_union.csv\")\n",
    "\n",
    "\n",
    "# Read the essential gene predictions\n",
    "prediction_ess = pd.read_csv(f\"../ess_number/filtered/{species}/common_essential_genes_{species}.csv\")\n",
    "prediction_ess.columns = ['lncRNA_id']\n",
    "p_ess = all_ess[all_ess['lncRNA_id'].isin(prediction_ess['lncRNA_id'])]\n",
    "\n",
    "# Filter out rows where 'gene_name' is '-'\n",
    "p_ess = p_ess[p_ess['gene_name'] != '-']\n",
    "\n",
    "# Apply the process_quoted_strings function to each row in the 'gene_name' column\n",
    "\n",
    "# Process and explode the 'gene_name' column\n",
    "ess_name = p_ess['gene_name'].str.split(';').explode().reset_index(drop=True)\n",
    "\n",
    "# Convert the set to a DataFrame\n",
    "ess_name_df = pd.DataFrame(list(ess_name), columns=['gene_name'])\n",
    "\n",
    "# Save the final union of essential gene names to a file\n",
    "ess_name_df.to_csv(f\"ess_name_{species}_intersection.txt\", index=False, header=None)\n",
    "\n",
    "print(\"Union of essential gene names saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union of gene names saved successfully.\n",
      "Union of gene names saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for species in ['human','mouse']:\n",
    "    # Read the essential gene predictions\n",
    "    all_lnc = pd.read_csv(f\"../../data/LPI/{species}/lncRNA.csv\")\n",
    "\n",
    "    # Filter out rows where 'gene_name' is '-'\n",
    "    all_lnc = all_lnc[all_lnc['gene_name'] != '-']\n",
    "\n",
    "    # Process and explode the 'gene_name' column\n",
    "    name = all_lnc['gene_name'].str.split(';').explode().reset_index(drop=True)\n",
    "\n",
    "    # Convert the set to a DataFrame\n",
    "    name_df = pd.DataFrame(list(name), columns=['gene_name'])\n",
    "\n",
    "    # Save the final union of essential gene names to a file\n",
    "    name_df.to_csv(f\"name_{species}.txt\", index=False, header=None)\n",
    "\n",
    "    print(\"Gene names saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic results of  Go Term(BP,CC,MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = 'human'\n",
    "if species == \"mouse\":\n",
    "\titem = ['heart', 'lung', 'brain', 'inter']\n",
    "else:\n",
    "\titem = ['heart', 'lung', 'stomach', 'inter']\n",
    "\n",
    "# Read the file\n",
    "for i in item:\n",
    "\tfile_path = f'./chart/{species}_{i}.csv'  \n",
    "\tdf = pd.read_csv(file_path)  \n",
    "\tdf = df[['Category', 'Term', 'P-Value', 'Fold Enrichment', 'FDR']]\n",
    "\n",
    "\t# Filter out rows with FDR >= 0.05 (non-significant GO terms)\n",
    "\tsignificant_df = df[df['FDR'] < 0.05]\n",
    "\tsignificant_df = significant_df[significant_df['Fold Enrichment'] > 1]\n",
    "\n",
    "\t# For each category, get the top 5 GO terms by sorting based on p-value\n",
    "\ttop_bp = significant_df[significant_df['Category'] == 'GOTERM_BP_DIRECT'].sort_values('P-Value').head(5)\n",
    "\ttop_cc = significant_df[significant_df['Category'] == 'GOTERM_CC_DIRECT'].sort_values('P-Value').head(5)\n",
    "\ttop_mf = significant_df[significant_df['Category'] == 'GOTERM_MF_DIRECT'].sort_values('P-Value').head(5)\n",
    "\tdf_go = pd.concat([top_bp, top_cc, top_mf], ignore_index=True)\n",
    "\tdf_go.to_csv(f\"./enrich_go/{species}_{i}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged 8 CSV files into go_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 目录下的八个CSV文件\n",
    "csv_files = [\n",
    "    \"./enrich_go/human_heart.csv\",\n",
    "    \"./enrich_go/human_lung.csv\",\n",
    "    \"./enrich_go/human_stomach.csv\",\n",
    "    \"./enrich_go/human_inter.csv\",\n",
    "    \"./enrich_go/mouse_heart.csv\",\n",
    "    \"./enrich_go/mouse_lung.csv\",\n",
    "    \"./enrich_go/mouse_brain.csv\",\n",
    "    \"./enrich_go/mouse_inter.csv\",\n",
    "]\n",
    "\n",
    "# 输出 Excel 文件路径\n",
    "output_excel_file = \"go_data.xlsx\"\n",
    "\n",
    "# 创建一个 Excel writer\n",
    "with pd.ExcelWriter(output_excel_file, engine='xlsxwriter') as writer:\n",
    "    for csv_file in csv_files:\n",
    "        # 读取每个CSV文件\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # 提取文件名作为 sheet 名（不含路径和扩展名）\n",
    "        sheet_name = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "        \n",
    "        # 将 CSV 数据写入 Excel 的每个 sheet\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"✅ Merged {len(csv_files)} CSV files into {output_excel_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esslnc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
