{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562b010a",
   "metadata": {},
   "source": [
    "### Step1 Get transcripts for lncRNA genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7453ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Human\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set the directory containing ensembl transcript data\n",
    "ensembl_dir = \"../../reference_lncRNA/human/transcript/ensembl/\"\n",
    "\n",
    "# Read LncBook and NONCODE transcript files\n",
    "cols = ['gene_id', 'transcript_id']\n",
    "noncodev5_trans = pd.read_csv('../../reference_lncRNA/human/transcript/NONCODEv5_human_hg38_lncRNA_trans.txt', sep='\\t', header=None, names=cols)\n",
    "noncodev6_trans = pd.read_csv('../../reference_lncRNA/human/transcript/NONCODEv6_human_hg38_lncRNA_trans.txt', sep='\\t', header=None, names=cols)\n",
    "\n",
    "# Read lncRNA ID data\n",
    "lncRNA = pd.read_csv('../../data/LPI/human/lncRNA.csv')\n",
    "lncRNA = lncRNA[['gene_id','gene_name', 'identifier']]\n",
    "\n",
    "# Initialize remaining lncRNA list\n",
    "remained_lncRNA = lncRNA[['gene_id','gene_name', 'identifier']].copy()\n",
    "\n",
    "# Function to remove matched rows\n",
    "def update_remained_lncRNA(df, matched_df):\n",
    "    \"\"\"Remove matched identifier from the remaining lncRNA list\"\"\"\n",
    "    updated_df = df[~df['identifier'].isin(matched_df['identifier'])]\n",
    "    return updated_df[['gene_id','gene_name', 'identifier']]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Get transcript by NONCODE (v6 and v5)\n",
    "trans_lnc_noncodev6 = pd.merge(remained_lncRNA, noncodev6_trans, left_on='identifier', right_on='gene_id', how='inner')\n",
    "results.append(trans_lnc_noncodev6)\n",
    "remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_noncodev6)\n",
    "\n",
    "trans_lnc_noncodev5 = pd.merge(remained_lncRNA, noncodev5_trans, left_on='identifier', right_on='gene_id', how='inner')\n",
    "results.append(trans_lnc_noncodev5)\n",
    "remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_noncodev5)\n",
    "\n",
    "# Extract version numbers and sort filenames in descending order\n",
    "def extract_version(filename):\n",
    "    match = re.search(r'GRCh38\\.(\\d+)_trans\\.txt', filename)\n",
    "    return int(match.group(1)) if match else -1  # Extract version number, default to -1 if no match\n",
    "\n",
    "ensembl_files = [f for f in os.listdir(ensembl_dir) if f.endswith(\".txt\")]\n",
    "sorted_ensembl_files = sorted(ensembl_files, key=extract_version, reverse=True)  # Sort by version number (descending)\n",
    "\n",
    "# Iterate through sorted ensembl transcript files\n",
    "for txt_file in sorted_ensembl_files:\n",
    "    file_path = os.path.join(ensembl_dir, txt_file)\n",
    "\n",
    "    # Read ensembl transcript file\n",
    "    ensembl_trans = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None,\n",
    "        names=['gene_id', 'gene_name', 'transcript_id']\n",
    "    )\n",
    "\n",
    "    trans_lnc_ensembl = pd.merge(\n",
    "        remained_lncRNA,\n",
    "        ensembl_trans[['gene_id', 'transcript_id']],\n",
    "        left_on='identifier', right_on='gene_id', how='inner'\n",
    "    )\n",
    "    results.append(trans_lnc_ensembl)\n",
    "    remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_ensembl)\n",
    "    \n",
    "for txt_file in sorted_ensembl_files:\n",
    "    file_path = os.path.join(ensembl_dir, txt_file)\n",
    "\n",
    "    # Read ensembl transcript file\n",
    "    ensembl_trans = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None,\n",
    "        names=['gene_id', 'gene_name', 'transcript_id']\n",
    "    )\n",
    "    \n",
    "    trans_lnc_symbol = pd.merge(\n",
    "        remained_lncRNA,\n",
    "        ensembl_trans[['gene_name', 'transcript_id']],\n",
    "        left_on='identifier', right_on='gene_name', how='inner'\n",
    "    )\n",
    "    results.append(trans_lnc_symbol)\n",
    "\n",
    "    # --- Update remained set ---\n",
    "    remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_symbol)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "trans_lnc = pd.concat(results, ignore_index=True)\n",
    "trans_lnc = trans_lnc[['identifier', 'transcript_id']]\n",
    "\n",
    "# Save results to file\n",
    "trans_lnc.drop_duplicates().to_csv('./human/lnc_trans.csv', index=False, header=['identifier','transcript_id'])\n",
    "\n",
    "remained_lncRNA.to_csv(\"./human/no_trans.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7f4a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Mouse\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set the directory containing ensembl transcript data\n",
    "ensembl_dir = \"../../reference_lncRNA/mouse/transcript/ensembl/\"\n",
    "\n",
    "# Read LncBook and NONCODE transcript files\n",
    "cols = ['gene_id', 'transcript_id']\n",
    "noncodev5_trans = pd.read_csv('../../reference_lncRNA/mouse/transcript/NONCODEv5_mouse_mm10_lncRNA_trans.txt', sep='\\t', header=None, names=cols)\n",
    "\n",
    "# Read lncRNA ID data\n",
    "lncRNA = pd.read_csv('../../data/LPI/mouse/lncRNA.csv')\n",
    "lncRNA = lncRNA[['gene_id','gene_name', 'identifier']]\n",
    "\n",
    "# Initialize remaining lncRNA list\n",
    "remained_lncRNA = lncRNA[['gene_id','gene_name', 'identifier']].copy()\n",
    "\n",
    "# Function to remove matched rows\n",
    "def update_remained_lncRNA(df, matched_df):\n",
    "    \"\"\"Remove matched identifier from the remaining lncRNA list\"\"\"\n",
    "    updated_df = df[~df['identifier'].isin(matched_df['identifier'])]\n",
    "    return updated_df[['gene_id','gene_name', 'identifier']]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Get transcript by NONCODE (v5)\n",
    "trans_lnc_noncodev5 = pd.merge(remained_lncRNA, noncodev5_trans, left_on='identifier', right_on='gene_id', how='inner')\n",
    "results.append(trans_lnc_noncodev5)\n",
    "remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_noncodev5)\n",
    "\n",
    "# Extract version numbers and sort filenames in descending order\n",
    "def extract_version(filename):\n",
    "    match = re.search(r'GRCm38\\.(\\d+)_trans\\.txt', filename)\n",
    "    return int(match.group(1)) if match else -1  # Extract version number, default to -1 if no match\n",
    "\n",
    "ensembl_files = [f for f in os.listdir(ensembl_dir) if re.match(r\"Mus_musculus\\.GRCm38\\.\\d+_trans\\.txt$\", f)]\n",
    "sorted_ensembl_files = sorted(ensembl_files, key=extract_version, reverse=True)  # Sort by version number (descending)\n",
    "\n",
    "# Iterate through sorted ensembl transcript files\n",
    "for txt_file in sorted_ensembl_files:\n",
    "    file_path = os.path.join(ensembl_dir, txt_file)\n",
    "\n",
    "    # Read ensembl transcript file\n",
    "    ensembl_trans = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None,\n",
    "        names=['gene_id', 'gene_name', 'transcript_id']\n",
    "    )\n",
    "\n",
    "    trans_lnc_ensembl = pd.merge(\n",
    "        remained_lncRNA,\n",
    "        ensembl_trans[['gene_id', 'transcript_id']],\n",
    "        left_on='identifier', right_on='gene_id', how='inner'\n",
    "    )\n",
    "    results.append(trans_lnc_ensembl)\n",
    "    remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_ensembl)\n",
    "    \n",
    "for txt_file in sorted_ensembl_files:\n",
    "    file_path = os.path.join(ensembl_dir, txt_file)\n",
    "\n",
    "    # Read ensembl transcript file\n",
    "    ensembl_trans = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None,\n",
    "        names=['gene_id', 'gene_name', 'transcript_id']\n",
    "    )\n",
    "    \n",
    "    trans_lnc_symbol = pd.merge(\n",
    "        remained_lncRNA,\n",
    "        ensembl_trans[['gene_name', 'transcript_id']],\n",
    "        left_on='identifier', right_on='gene_name', how='inner'\n",
    "    )\n",
    "    results.append(trans_lnc_symbol)\n",
    "\n",
    "    # --- Update remained set ---\n",
    "    remained_lncRNA = update_remained_lncRNA(remained_lncRNA, trans_lnc_symbol)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "trans_lnc = pd.concat(results, ignore_index=True)\n",
    "trans_lnc = trans_lnc[['identifier', 'transcript_id']]\n",
    "\n",
    "# Save results to file\n",
    "trans_lnc.drop_duplicates().to_csv('./mouse/lnc_trans.csv', index=False, header=None)\n",
    "\n",
    "remained_lncRNA.to_csv(\"./mouse/no_trans.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c76f23",
   "metadata": {},
   "source": [
    "### Step2 Obtain the transcript sequences and filter out transcripts longer than 20,000 nt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a248b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define sequence length limit\n",
    "MAX_SEQUENCE_LENGTH = 20000  # Remove genes if any transcript exceeds this length\n",
    "\n",
    "# Load the mapping file and initialize dictionaries\n",
    "def load_transcript_ids(mapping_file):\n",
    "    df = pd.read_csv(mapping_file, dtype=str, header=None, names=['identifier', 'transcript_id'])\n",
    "    \n",
    "    gene_to_transcripts = {}  # Store mapping from gene ID to transcript ID list\n",
    "    transcript_to_gene = {}   # Store mapping from transcript ID to gene ID\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        gene_id = row['identifier'].strip()\n",
    "        transcript_id = row['transcript_id'].strip()\n",
    "\n",
    "        if gene_id not in gene_to_transcripts:\n",
    "            gene_to_transcripts[gene_id] = set()\n",
    "        gene_to_transcripts[gene_id].add(transcript_id)\n",
    "        transcript_to_gene[transcript_id] = gene_id\n",
    "\n",
    "    return gene_to_transcripts, transcript_to_gene\n",
    "\n",
    "# Fetch sequences for transcript IDs from a list of FASTA files\n",
    "def fetch_sequences(fasta_files, gene_to_transcripts):\n",
    "    found_transcripts = {}  # Store found transcript sequences\n",
    "    missing_genes = set()   # Store genes whose sequences are missing\n",
    "    oversized_genes = set() # Store genes that contain transcripts exceeding MAX_SEQUENCE_LENGTH\n",
    "\n",
    "    # Create a set of all transcript IDs that need to be found\n",
    "    all_transcript_ids = {tid for tids in gene_to_transcripts.values() for tid in tids}\n",
    "    needed_ids = all_transcript_ids.copy()  # Copy set to track missing IDs\n",
    "\n",
    "    for file in fasta_files:\n",
    "        print(f\"Checking file: {file}\")  # Debugging output\n",
    "        if not needed_ids:  # Stop early if all sequences have been found\n",
    "            break\n",
    "        for record in SeqIO.parse(file, \"fasta\"):\n",
    "            if record.id in needed_ids:\n",
    "                if len(record.seq) > MAX_SEQUENCE_LENGTH:\n",
    "                    oversized_genes.add(transcript_to_gene[record.id])  # Mark gene for removal\n",
    "                else:\n",
    "                    found_transcripts[record.id] = record.seq  # Store valid transcript\n",
    "                needed_ids.remove(record.id)  # Remove found ID from the set\n",
    "\n",
    "    # Identify genes for which all transcripts are missing\n",
    "    for gene_id, transcript_ids in gene_to_transcripts.items():\n",
    "        if not all(tid in found_transcripts for tid in transcript_ids):  # If any transcripts of a gene are missing\n",
    "            missing_genes.add(gene_id)\n",
    "\n",
    "    # Combine genes to remove: those missing and those with oversized transcripts\n",
    "    genes_to_remove = missing_genes.union(oversized_genes)\n",
    "\n",
    "    # Remove the affected genes and their transcripts\n",
    "    for gene_id in genes_to_remove:\n",
    "        for tid in gene_to_transcripts[gene_id]:  # Iterate through all transcripts of the gene\n",
    "            found_transcripts.pop(tid, None)  # Ensure all associated transcripts are removed\n",
    "\n",
    "    # Filter out removed genes from the gene-to-transcript dictionary\n",
    "    filtered_gene_to_transcripts = {gene: trans for gene, trans in gene_to_transcripts.items() if gene not in genes_to_remove}\n",
    "\n",
    "    return found_transcripts, filtered_gene_to_transcripts\n",
    "\n",
    "# Write the found sequences to a new FASTA file\n",
    "def write_fasta(sequences, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for trans_id, seq in sequences.items():\n",
    "            SeqIO.write(SeqIO.SeqRecord(seq, id=trans_id, description=\"\"), f, \"fasta\")\n",
    "\n",
    "# Write the filtered gene-to-transcript mappings to a new file\n",
    "def write_filtered_mapping(filtered_gene_to_transcripts, output_mapping_file, sequences):\n",
    "    with open(output_mapping_file, \"w\") as f:\n",
    "        for gene_id, transcript_ids in filtered_gene_to_transcripts.items():\n",
    "            # keep only transcripts that actually have sequences\n",
    "            kept = [tid for tid in transcript_ids if tid in sequences]\n",
    "            for tid in kept:\n",
    "                f.write(f\"{gene_id},{tid}\\n\")\n",
    "\n",
    "# File paths and execution\n",
    "mapping_file = \"./human/lnc_trans.csv\"\n",
    "base_directory = \"../../reference_lncRNA/human/fasta/\"\n",
    "processed_ensembl_dir = \"../../reference_lncRNA/human/fasta/processed_ensembl/\"\n",
    "\n",
    "def extract_version(filename):\n",
    "    match = re.search(r'v(\\d+)', filename)\n",
    "    #match = re.search(r'GRCh38\\.(\\d+).ncrna_processed\\.fa', filename)\n",
    "    return int(match.group(1)) if match else -1  # Extract version number, default to -1 if no match\n",
    "\n",
    "# Get all .fa files in processedensembl directory\n",
    "processed_ensembl_fa_files = [f for f in os.listdir(processed_ensembl_dir) if f.endswith(\".fa\")]\n",
    "sorted_ensembl_files = [os.path.join(processed_ensembl_dir, f) for f in sorted(processed_ensembl_fa_files, key=extract_version, reverse=True)]\n",
    "\n",
    "fasta_files = [\n",
    "    os.path.join(base_directory, \"NONCODEv6_human_processed.fa\"),\n",
    "    os.path.join(base_directory, \"NONCODEv5_human_processed.fa\")\n",
    "] + sorted_ensembl_files  # Add dynamically found files\n",
    "\n",
    "output_fasta_file = \"./human/transcript_sequences.fasta\"\n",
    "output_mapping_file = \"./human/filtered_lnc_trans.csv\"\n",
    "\n",
    "# Load required transcript IDs and gene mappings\n",
    "gene_to_transcripts, transcript_to_gene = load_transcript_ids(mapping_file)\n",
    "\n",
    "# Fetch sequences and remove missing/oversized genes\n",
    "sequences, filtered_gene_to_transcripts = fetch_sequences(fasta_files, gene_to_transcripts)\n",
    "\n",
    "# Write the filtered sequences to output FASTA file\n",
    "write_fasta(sequences, output_fasta_file)\n",
    "\n",
    "# Write the filtered gene-transcript mappings to a new file\n",
    "write_filtered_mapping(filtered_gene_to_transcripts, output_mapping_file, sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c76facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: ../../reference_lncRNA/mouse/fasta/NONCODEv6_mouse_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/NONCODEv5_mouse_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v100.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v99.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v98.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v97.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v96.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v95.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v94.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v93.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v92.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v91.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v90.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v89.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v88.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v87.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v86.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v85.ncrna_processed.fa\n",
      "Checking file: ../../reference_lncRNA/mouse/fasta/processed_ensembl/Mus_musculus.GRCm38.v84.ncrna_processed.fa\n"
     ]
    }
   ],
   "source": [
    "# Mouse\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define sequence length limit\n",
    "MAX_SEQUENCE_LENGTH = 20000  # Remove genes if any transcript exceeds this length\n",
    "\n",
    "# Load the mapping file and initialize dictionaries\n",
    "def load_transcript_ids(mapping_file):\n",
    "    df = pd.read_csv(mapping_file, dtype=str, header=None, names=['lncRNA_id', 'transcript_id'])\n",
    "    \n",
    "    gene_to_transcripts = {}  # Store mapping from gene ID to transcript ID list\n",
    "    transcript_to_gene = {}   # Store mapping from transcript ID to gene ID\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        gene_id = row['lncRNA_id'].strip()\n",
    "        transcript_id = row['transcript_id'].strip()\n",
    "\n",
    "        if gene_id not in gene_to_transcripts:\n",
    "            gene_to_transcripts[gene_id] = set()\n",
    "        gene_to_transcripts[gene_id].add(transcript_id)\n",
    "        transcript_to_gene[transcript_id] = gene_id\n",
    "\n",
    "    return gene_to_transcripts, transcript_to_gene\n",
    "\n",
    "# Fetch sequences for transcript IDs from a list of FASTA files\n",
    "def fetch_sequences(fasta_files, gene_to_transcripts):\n",
    "    found_transcripts = {}  # Store found transcript sequences\n",
    "    missing_genes = set()   # Store genes whose sequences are missing\n",
    "    oversized_genes = set() # Store genes that contain transcripts exceeding MAX_SEQUENCE_LENGTH\n",
    "\n",
    "    # Create a set of all transcript IDs that need to be found\n",
    "    all_transcript_ids = {tid for tids in gene_to_transcripts.values() for tid in tids}\n",
    "    needed_ids = all_transcript_ids.copy()  # Copy set to track missing IDs\n",
    "\n",
    "    for file in fasta_files:\n",
    "        print(f\"Checking file: {file}\")  # Debugging output\n",
    "        if not needed_ids:  # Stop early if all sequences have been found\n",
    "            break\n",
    "        for record in SeqIO.parse(file, \"fasta\"):\n",
    "            if record.id in needed_ids:\n",
    "                if len(record.seq) > MAX_SEQUENCE_LENGTH:\n",
    "                    oversized_genes.add(transcript_to_gene[record.id])  # Mark gene for removal\n",
    "                else:\n",
    "                    found_transcripts[record.id] = record.seq  # Store valid transcript\n",
    "                needed_ids.remove(record.id)  # Remove found ID from the set\n",
    "\n",
    "    # Identify genes for which all transcripts are missing\n",
    "    for gene_id, transcript_ids in gene_to_transcripts.items():\n",
    "        if not all(tid in found_transcripts for tid in transcript_ids):  # If any transcripts of a gene are missing\n",
    "            missing_genes.add(gene_id)\n",
    "\n",
    "    # Combine genes to remove: those missing and those with oversized transcripts\n",
    "    genes_to_remove = missing_genes.union(oversized_genes)\n",
    "\n",
    "    # Remove the affected genes and their transcripts\n",
    "    for gene_id in genes_to_remove:\n",
    "        for tid in gene_to_transcripts[gene_id]:  # Iterate through all transcripts of the gene\n",
    "            found_transcripts.pop(tid, None)  # Ensure all associated transcripts are removed\n",
    "\n",
    "    # Filter out removed genes from the gene-to-transcript dictionary\n",
    "    filtered_gene_to_transcripts = {gene: trans for gene, trans in gene_to_transcripts.items() if gene not in genes_to_remove}\n",
    "\n",
    "    return found_transcripts, filtered_gene_to_transcripts\n",
    "\n",
    "# Write the found sequences to a new FASTA file\n",
    "def write_fasta(sequences, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for trans_id, seq in sequences.items():\n",
    "            SeqIO.write(SeqIO.SeqRecord(seq, id=trans_id, description=\"\"), f, \"fasta\")\n",
    "\n",
    "# Write the filtered gene-to-transcript mappings to a new file\n",
    "def write_filtered_mapping(filtered_gene_to_transcripts, output_mapping_file, sequences):\n",
    "    with open(output_mapping_file, \"w\") as f:\n",
    "        for gene_id, transcript_ids in filtered_gene_to_transcripts.items():\n",
    "            # keep only transcripts that actually have sequences\n",
    "            kept = [tid for tid in transcript_ids if tid in sequences]\n",
    "            for tid in kept:\n",
    "                f.write(f\"{gene_id},{tid}\\n\")\n",
    "\n",
    "# File paths and execution\n",
    "mapping_file = \"./mouse/lnc_trans.csv\"\n",
    "base_directory = \"../../reference_lncRNA/mouse/fasta/\"\n",
    "processed_ensembl_dir = \"../../reference_lncRNA/mouse/fasta/processed_ensembl/\"\n",
    "\n",
    "def extract_version(filename):\n",
    "    match = re.search(r'v(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else -1  # Extract version number, default to -1 if no match\n",
    "\n",
    "# Get all .fa files in processedensembl directory\n",
    "processed_ensembl_fa_files = [f for f in os.listdir(processed_ensembl_dir) if f.endswith(\".fa\")]\n",
    "sorted_ensembl_files = [os.path.join(processed_ensembl_dir, f) for f in sorted(processed_ensembl_fa_files, key=extract_version, reverse=True)]\n",
    "\n",
    "fasta_files = [\n",
    "    os.path.join(base_directory, \"NONCODEv6_mouse_processed.fa\"),\n",
    "    os.path.join(base_directory, \"NONCODEv5_mouse_processed.fa\")\n",
    "] + sorted_ensembl_files  # Add dynamically found files\n",
    "\n",
    "output_fasta_file = \"./mouse/transcript_sequences.fasta\"\n",
    "output_mapping_file = \"./mouse/filtered_lnc_trans.csv\"\n",
    "\n",
    "# Load required transcript IDs and gene mappings\n",
    "gene_to_transcripts, transcript_to_gene = load_transcript_ids(mapping_file)\n",
    "\n",
    "# Fetch sequences and remove missing/oversized genes\n",
    "sequences, filtered_gene_to_transcripts = fetch_sequences(fasta_files, gene_to_transcripts)\n",
    "\n",
    "# Write the filtered sequences to output FASTA file\n",
    "write_fasta(sequences, output_fasta_file)\n",
    "\n",
    "# Write the filtered gene-transcript mappings to a new file\n",
    "write_filtered_mapping(filtered_gene_to_transcripts, output_mapping_file, sequences)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
