{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2341cf7c",
   "metadata": {},
   "source": [
    "#### Deduplication for lncRNA nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c40d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set the directory containing ensembl data\n",
    "ensembl_dir = \"../../reference_lncRNA/human/bed/ensembl/\"\n",
    "\n",
    "# Read lncRNA ID and gene_name information\n",
    "lncRNA = pd.read_csv('../../data/LPI/human/lncRNA.csv')\n",
    "\n",
    "# Read NONCODE BED files\n",
    "noncodev5_bed = pd.read_csv('../../reference_lncRNA/human/bed/NONCODEv5_hg38.lncRNAGene.bed', sep='\\t', \n",
    "                            header=None, names=['chr', 'start', 'end', 'gene_id', 'score', 'strand'])\n",
    "noncodev6_bed = pd.read_csv('../../reference_lncRNA/human/bed/NONCODEv6_hg38.lncRNAGene.bed', sep='\\t', \n",
    "                            header=None, names=['chr', 'start', 'end', 'gene_id', 'score', 'strand'])\n",
    "\n",
    "# Initialize remaining lncRNA list\n",
    "remained_lncRNA = lncRNA[['gene_id', 'gene_name', 'identifier']].copy()\n",
    "results = []\n",
    "\n",
    "# Get genomic position by noncode_id (noncodev6)\n",
    "pos_lnc_noncodev6 = pd.merge(\n",
    "    remained_lncRNA,\n",
    "    noncodev6_bed[['chr', 'start', 'end', 'strand', 'gene_id']],\n",
    "    left_on='identifier',\n",
    "    right_on='gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "results.append(pos_lnc_noncodev6)\n",
    "remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_noncodev6['identifier'])]\n",
    "\n",
    "# Get genomic position by noncode_id (noncodev5)\n",
    "pos_lnc_noncodev5 = pd.merge(\n",
    "    remained_lncRNA,\n",
    "    noncodev5_bed[['chr', 'start', 'end', 'strand', 'gene_id']],\n",
    "    left_on='identifier',\n",
    "    right_on='gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "results.append(pos_lnc_noncodev5)\n",
    "remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_noncodev5['identifier'])]\n",
    "\n",
    "# Get genomic position by ensembl_id & gene_name\n",
    "# **STEP 1: Extract the version number from BED file**\n",
    "def extract_version(filename):\n",
    "    match = re.search(r'GRCh38\\.(\\d+)\\.bed', filename) # ensembl\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# **STEP 2: Get all BED files and sort them by version number**\n",
    "bed_files = [f for f in os.listdir(ensembl_dir) if f.endswith(\".bed\")]\n",
    "bed_files_sorted = sorted(bed_files, key=extract_version, reverse=True)  # Sort by version number in descending order\n",
    "\n",
    "# **STEP 3: Iterate over sorted BED files**\n",
    "for bed_file in bed_files_sorted:\n",
    "    bed_path = os.path.join(ensembl_dir, bed_file)\n",
    "\n",
    "    # Read ensembl BED file\n",
    "    ensembl_bed = pd.read_csv(bed_path, sep='\\t', header=None, \n",
    "                              names=['chr', 'start', 'end', 'gene_name', 'gene_id', 'strand'])\n",
    "\n",
    "    # Match by gene_id\n",
    "    pos_lnc_ensembl = pd.merge(remained_lncRNA, \n",
    "                               ensembl_bed[['chr', 'start', 'end', 'strand', 'gene_id']], \n",
    "                               left_on='identifier',\n",
    "                               right_on='gene_id', how='inner')\n",
    "    results.append(pos_lnc_ensembl)\n",
    "    remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_ensembl['identifier'])]\n",
    "\n",
    "for bed_file in bed_files_sorted:\n",
    "    bed_path = os.path.join(ensembl_dir, bed_file)\n",
    "\n",
    "    # Read ensembl BED file\n",
    "    ensembl_bed = pd.read_csv(bed_path, sep='\\t', header=None, \n",
    "                              names=['chr', 'start', 'end', 'gene_name', 'gene_id', 'strand'])\n",
    "\n",
    "    # Match by gene_name\n",
    "    pos_lnc_gene_name = pd.merge(remained_lncRNA, \n",
    "                                 ensembl_bed[['chr', 'start', 'end', 'strand', 'gene_name']], \n",
    "                                 left_on='identifier',\n",
    "                                 right_on='gene_name', how='inner')\n",
    "    remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_gene_name['identifier'])]\n",
    "    results.append(pos_lnc_gene_name)\n",
    "\n",
    "# Combine all results\n",
    "pos_lnc = pd.concat(results, ignore_index=True).drop_duplicates(subset=['identifier'])\n",
    "\n",
    "# Save remaining lncRNAs without genomic positions\n",
    "remained_lncRNA.drop_duplicates().to_csv('human_lnc_no_pos.csv', index=False)\n",
    "\n",
    "# Create BED6 format output: chr, start, end, name, score, strand\n",
    "pos_lnc_bed = pos_lnc[['chr', 'start', 'end', 'identifier', 'strand']].copy()\n",
    "pos_lnc_bed['score'] = 0\n",
    "\n",
    "# Reorder columns to BED6 format\n",
    "pos_lnc_bed = pos_lnc_bed[['chr', 'start', 'end', 'identifier', 'score', 'strand']]\n",
    "\n",
    "# Save as BED (tab-delimited, no header)\n",
    "pos_lnc_bed.to_csv('human_lncRNA_0-based.bed', sep='\\t', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set the directory containing ensembl data\n",
    "ensembl_dir = \"../../reference_lncRNA/mouse/bed/ensembl/\"\n",
    "\n",
    "# Read lncRNA ID and gene_name information\n",
    "lncRNA = pd.read_csv('../../data/LPI/mouse/lncRNA.csv')\n",
    "\n",
    "# Read NONCODE BED files\n",
    "noncodev5_bed = pd.read_csv('../../reference_lncRNA/mouse/bed/NONCODEv5_mm10.lncRNAGene.bed', sep='\\t', \n",
    "                            header=None, names=['chr', 'start', 'end', 'gene_id', 'score', 'strand'])\n",
    "noncodev6_bed = pd.read_csv('../../reference_lncRNA/mouse/bed/NONCODEv6_mm10.lncRNAGene.bed', sep='\\t', \n",
    "                            header=None, names=['chr', 'start', 'end', 'gene_id', 'score', 'strand'])\n",
    "\n",
    "# Initialize remaining lncRNA list\n",
    "remained_lncRNA = lncRNA[['gene_id', 'gene_name', 'identifier']].copy()\n",
    "results = []\n",
    "\n",
    "# Get genomic position by noncode_id (noncodev6)\n",
    "pos_lnc_noncodev6 = pd.merge(\n",
    "    remained_lncRNA,\n",
    "    noncodev6_bed[['chr', 'start', 'end', 'strand', 'gene_id']],\n",
    "    left_on='identifier',\n",
    "    right_on='gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "results.append(pos_lnc_noncodev6)\n",
    "remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_noncodev6['identifier'])]\n",
    "\n",
    "# Get genomic position by noncode_id (noncodev5)\n",
    "pos_lnc_noncodev5 = pd.merge(\n",
    "    remained_lncRNA,\n",
    "    noncodev5_bed[['chr', 'start', 'end', 'strand', 'gene_id']],\n",
    "    left_on='identifier',\n",
    "    right_on='gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "results.append(pos_lnc_noncodev5)\n",
    "remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_noncodev5['identifier'])]\n",
    "\n",
    "# Get genomic position by ensembl_id & gene_name\n",
    "# **STEP 1: Extract the version number from BED file**\n",
    "def extract_version(filename):\n",
    "    match = re.search(r'GRCm38\\.(\\d+)\\.bed', filename) # ensembl\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# **STEP 2: Get all BED files and sort them by version number**\n",
    "bed_files = [f for f in os.listdir(ensembl_dir) if re.match(r\"Mus_musculus\\.GRCm38\\.\\d+\\.bed$\", f)]\n",
    "bed_files_sorted = sorted(bed_files, key=extract_version, reverse=True)  # Sort by version number in descending order\n",
    "\n",
    "# **STEP 3: Iterate over sorted BED files**\n",
    "for bed_file in bed_files_sorted:\n",
    "    bed_path = os.path.join(ensembl_dir, bed_file)\n",
    "\n",
    "    # Read ensembl BED file\n",
    "    ensembl_bed = pd.read_csv(bed_path, sep='\\t', header=None, \n",
    "                              names=['chr', 'start', 'end', 'gene_name', 'gene_id', 'strand'])\n",
    "\n",
    "    # Match by gene_id\n",
    "    pos_lnc_ensembl = pd.merge(remained_lncRNA, \n",
    "                               ensembl_bed[['chr', 'start', 'end', 'strand', 'gene_id']], \n",
    "                               left_on='identifier',\n",
    "                               right_on='gene_id', how='inner')\n",
    "    results.append(pos_lnc_ensembl)\n",
    "    remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_ensembl['identifier'])]\n",
    "\n",
    "for bed_file in bed_files_sorted:\n",
    "    bed_path = os.path.join(ensembl_dir, bed_file)\n",
    "\n",
    "    # Read ensembl BED file\n",
    "    ensembl_bed = pd.read_csv(bed_path, sep='\\t', header=None, \n",
    "                              names=['chr', 'start', 'end', 'gene_name', 'gene_id', 'strand'])\n",
    "\n",
    "    # Match by gene_name\n",
    "    pos_lnc_gene_name = pd.merge(remained_lncRNA, \n",
    "                                 ensembl_bed[['chr', 'start', 'end', 'strand', 'gene_name']], \n",
    "                                 left_on='identifier',\n",
    "                                 right_on='gene_name', how='inner')\n",
    "    remained_lncRNA = remained_lncRNA[~remained_lncRNA['identifier'].isin(pos_lnc_gene_name['identifier'])]\n",
    "    results.append(pos_lnc_gene_name)\n",
    "\n",
    "# Combine all results\n",
    "pos_lnc = pd.concat(results, ignore_index=True).drop_duplicates(subset=['identifier'])\n",
    "\n",
    "# Save remaining lncRNAs without genomic positions\n",
    "remained_lncRNA.drop_duplicates().to_csv('mouse_lnc_no_pos.csv', index=False)\n",
    "\n",
    "# Create BED6 format output: chr, start, end, name, score, strand\n",
    "pos_lnc_bed = pos_lnc[['chr', 'start', 'end', 'identifier', 'strand']].copy()\n",
    "pos_lnc_bed['score'] = 0\n",
    "\n",
    "# Reorder columns to BED6 format\n",
    "pos_lnc_bed = pos_lnc_bed[['chr', 'start', 'end', 'identifier', 'score', 'strand']]\n",
    "\n",
    "# Save as BED (tab-delimited, no header)\n",
    "pos_lnc_bed.to_csv('mouse_lncRNA_0-based.bed', sep='\\t', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18910a6b",
   "metadata": {},
   "source": [
    "- Run ./get_overlap.sh to find duplicate lncRNA nodes.\n",
    "- ./get_overlap.sh human_lncRNA_0-based.bed human_overlap.txt\n",
    "- ./get_overlap.sh mouse_lncRNA_0-based.bed mouse_overlap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "species = \"human\"\n",
    "\n",
    "bed_file = \"human_lncRNA_0-based.bed\"              # Input BED6: chr start end identifier score strand\n",
    "overlap_file = f\"{species}_overlap.txt\"            # Overlap pairs: A B (may contain AB/BA redundancy)\n",
    "lpi_file = f\"../../data/LPI/{species}/lpi.csv\"     # LPI: lncRNA_id, protein_id (2 columns)\n",
    "\n",
    "# NEW: lncRNAs without genomic positions\n",
    "no_pos_file = \"human_lnc_no_pos.csv\"\n",
    "\n",
    "# Output files\n",
    "out_bed = f\"../../data/LPI/{species}/lncRNA_dedup.bed\"\n",
    "out_mapping = f\"../../data/LPI/{species}/lncRNA_mapping.csv\"\n",
    "out_lpi = f\"../../data/LPI/{species}/lpi_dedup.csv\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helper: chromosome sorting\n",
    "# =========================\n",
    "def chr_sort_key(c):\n",
    "    \"\"\"\n",
    "    Sort chromosomes in a human-friendly way:\n",
    "    chr1..chr22, chrX, chrY, chrM.\n",
    "    Works for both 'chr1' and '1' styles.\n",
    "    \"\"\"\n",
    "    c = str(c)\n",
    "    c2 = c.replace(\"chr\", \"\")\n",
    "    if c2.isdigit():\n",
    "        return (0, int(c2))\n",
    "    if c2 == \"X\":\n",
    "        return (1, 23)\n",
    "    if c2 == \"Y\":\n",
    "        return (1, 24)\n",
    "    if c2 in (\"M\", \"MT\"):\n",
    "        return (2, 25)\n",
    "    return (3, c2)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) Load lncRNAs without positions\n",
    "# =========================\n",
    "df_no_pos = pd.read_csv(no_pos_file)\n",
    "no_pos_ids = set(df_no_pos[\"identifier\"].astype(str))\n",
    "\n",
    "print(f\"[Info] Loaded {len(no_pos_ids)} lncRNAs without genomic positions from {no_pos_file}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Load BED\n",
    "# =========================\n",
    "df_bed = pd.read_csv(\n",
    "    bed_file, sep=\"\\t\", header=None,\n",
    "    names=[\"chr\", \"start\", \"end\", \"identifier\", \"score\", \"strand\"]\n",
    ")\n",
    "\n",
    "# Index by identifier for quick lookup\n",
    "bed_index = df_bed.set_index(\"identifier\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Load overlap pairs\n",
    "# =========================\n",
    "merge_pairs = pd.read_csv(overlap_file, sep=r\"\\s+\", header=None, names=[\"A\", \"B\"])\n",
    "merge_pairs = merge_pairs[merge_pairs[\"A\"] != merge_pairs[\"B\"]].copy()  # remove self-pairs\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Union-Find to group overlaps\n",
    "# =========================\n",
    "parent = {}\n",
    "\n",
    "def find(x):\n",
    "    parent.setdefault(x, x)\n",
    "    if parent[x] != x:\n",
    "        parent[x] = find(parent[x])\n",
    "    return parent[x]\n",
    "\n",
    "def union(x, y):\n",
    "    rx, ry = find(x), find(y)\n",
    "    if rx != ry:\n",
    "        parent[ry] = rx\n",
    "\n",
    "# Union all pairs (AB/BA redundancy does not affect final groups)\n",
    "for a, b in zip(merge_pairs[\"A\"], merge_pairs[\"B\"]):\n",
    "    union(a, b)\n",
    "\n",
    "# Build groups\n",
    "groups = defaultdict(set)\n",
    "all_ids_in_pairs = set(merge_pairs[\"A\"]).union(set(merge_pairs[\"B\"]))\n",
    "for gid in all_ids_in_pairs:\n",
    "    groups[find(gid)].add(gid)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Build clusters using union coordinates (no representative needed)\n",
    "# =========================\n",
    "cluster_candidates = []  # each item: dict with chr/start/end/strand and member list\n",
    "\n",
    "for group in groups.values():\n",
    "    # Keep only members existing in BED (no_pos_ids will naturally be excluded)\n",
    "    members = [m for m in group if m in bed_index.index]\n",
    "    if len(members) == 0:\n",
    "        continue\n",
    "\n",
    "    group_df = bed_index.loc[members].copy()\n",
    "\n",
    "    # Union range\n",
    "    u_chr = group_df[\"chr\"].iloc[0]\n",
    "    u_strand = group_df[\"strand\"].iloc[0]\n",
    "    u_start = int(group_df[\"start\"].min())\n",
    "    u_end = int(group_df[\"end\"].max())\n",
    "\n",
    "    # Consistency check (should be consistent because bedtools used -s)\n",
    "    if len(set(group_df[\"chr\"])) != 1 or len(set(group_df[\"strand\"])) != 1:\n",
    "        print(f\"[Warning] Inconsistent chr/strand in group: {members}\")\n",
    "\n",
    "    members_sorted = sorted(members)\n",
    "\n",
    "    cluster_candidates.append({\n",
    "        \"chr\": u_chr,\n",
    "        \"start\": u_start,\n",
    "        \"end\": u_end,\n",
    "        \"strand\": u_strand,\n",
    "        \"members\": members_sorted\n",
    "    })\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Add singleton genes as clusters (not in any overlap group)\n",
    "# =========================\n",
    "merged_members = set().union(*[set(v) for v in groups.values()]) if groups else set()\n",
    "all_ids = set(df_bed[\"identifier\"])\n",
    "singleton_ids = all_ids - merged_members\n",
    "\n",
    "singleton_ids_sorted = sorted(\n",
    "    list(singleton_ids),\n",
    "    key=lambda x: (\n",
    "        chr_sort_key(bed_index.loc[x, \"chr\"]),\n",
    "        int(bed_index.loc[x, \"start\"]),\n",
    "        int(bed_index.loc[x, \"end\"]),\n",
    "        str(bed_index.loc[x, \"strand\"]),\n",
    "        x\n",
    "    )\n",
    ")\n",
    "\n",
    "for sid in singleton_ids_sorted:\n",
    "    row = bed_index.loc[sid]\n",
    "    cluster_candidates.append({\n",
    "        \"chr\": row[\"chr\"],\n",
    "        \"start\": int(row[\"start\"]),\n",
    "        \"end\": int(row[\"end\"]),\n",
    "        \"strand\": row[\"strand\"],\n",
    "        \"members\": [sid]\n",
    "    })\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) Assign incremental lncRNA_id (stable ordering)\n",
    "# =========================\n",
    "cluster_candidates_sorted = sorted(\n",
    "    cluster_candidates,\n",
    "    key=lambda x: (\n",
    "        chr_sort_key(x[\"chr\"]),\n",
    "        x[\"start\"],\n",
    "        x[\"end\"],\n",
    "        x[\"strand\"],\n",
    "        \";\".join(x[\"members\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "cluster_rows = []         \n",
    "mapping_long_rows = []    \n",
    "old_to_new = {}           \n",
    "\n",
    "for i, c in enumerate(cluster_candidates_sorted, start=1):\n",
    "    lncRNA_id = f\"l{i:06d}\"\n",
    "\n",
    "    # Record BED row\n",
    "    cluster_rows.append({\n",
    "        \"chr\": c[\"chr\"],\n",
    "        \"start\": c[\"start\"],\n",
    "        \"end\": c[\"end\"],\n",
    "        \"lncRNA_id\": lncRNA_id,\n",
    "        \"score\": 0,\n",
    "        \"strand\": c[\"strand\"]\n",
    "    })\n",
    "\n",
    "    # Record long mapping rows and dictionary mapping\n",
    "    for m in c[\"members\"]:\n",
    "        mapping_long_rows.append({\"lncRNA_id\": lncRNA_id, \"member_id\": m})\n",
    "        old_to_new[m] = lncRNA_id\n",
    "\n",
    "df_cluster_bed = pd.DataFrame(cluster_rows)\n",
    "df_mapping_long = pd.DataFrame(mapping_long_rows)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) Save BED6 and mapping table\n",
    "# =========================\n",
    "df_cluster_bed = df_cluster_bed.sort_values(\n",
    "    by=[\"chr\", \"start\", \"end\", \"strand\", \"lncRNA_id\"],\n",
    "    key=lambda col: col.map(chr_sort_key) if col.name == \"chr\" else col\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_mapping_long = df_mapping_long.sort_values([\"lncRNA_id\", \"member_id\"]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_cluster_bed[[\"chr\", \"start\", \"end\", \"lncRNA_id\", \"score\", \"strand\"]].to_csv(\n",
    "    out_bed, sep=\"\\t\", header=False, index=False\n",
    ")\n",
    "\n",
    "df_mapping_long.to_csv(out_mapping, index=False)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8) Update LPI: remove no-pos lncRNAs and map identifiers -> lncRNA_id\n",
    "# =========================\n",
    "df_lpi = pd.read_csv(lpi_file)\n",
    "\n",
    "lnc_col = df_lpi.columns[0]\n",
    "prot_col = df_lpi.columns[1]\n",
    "\n",
    "# Step 8.1: remove interactions involving no-pos lncRNAs BEFORE mapping\n",
    "df_lpi = df_lpi[~df_lpi[lnc_col].astype(str).isin(no_pos_ids)].copy()\n",
    "\n",
    "# Step 8.2: map lncRNA identifier to new lncRNA_id\n",
    "df_lpi[lnc_col] = df_lpi[lnc_col].map(lambda x: old_to_new.get(x, x))\n",
    "\n",
    "# Step 8.3: remove any interactions that still cannot be mapped (optional)\n",
    "# If you only want rows where lncRNA_id is a valid cluster id:\n",
    "valid_cluster_ids = set(df_cluster_bed[\"lncRNA_id\"])\n",
    "df_lpi = df_lpi[df_lpi[lnc_col].isin(valid_cluster_ids)].copy()\n",
    "\n",
    "# Step 8.4: deduplicate\n",
    "df_lpi = df_lpi.drop_duplicates(subset=[lnc_col, prot_col]).reset_index(drop=True)\n",
    "\n",
    "df_lpi.columns=['lncRNA_id','protein']\n",
    "df_lpi.to_csv(out_lpi, index=False)\n",
    "\n",
    "\n",
    "print(\"✅ Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "species = \"mouse\"\n",
    "\n",
    "bed_file = \"mouse_lncRNA_0-based.bed\"              # Input BED6: chr start end identifier score strand\n",
    "overlap_file = f\"{species}_overlap.txt\"            # Overlap pairs: A B (may contain AB/BA redundancy)\n",
    "lpi_file = f\"../../data/LPI/{species}/lpi.csv\"     # LPI: lncRNA_id, protein_id (2 columns)\n",
    "\n",
    "# NEW: lncRNAs without genomic positions\n",
    "no_pos_file = \"mouse_lnc_no_pos.csv\"\n",
    "\n",
    "# Output files\n",
    "out_bed = f\"../../data/LPI/{species}/lncRNA_dedup.bed\"\n",
    "out_mapping = f\"../../data/LPI/{species}/lncRNA_mapping.csv\"\n",
    "out_lpi = f\"../../data/LPI/{species}/lpi_dedup.csv\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helper: chromosome sorting\n",
    "# =========================\n",
    "def chr_sort_key(c):\n",
    "    \"\"\"\n",
    "    Sort chromosomes in a mouse-friendly way:\n",
    "    chr1..chr22, chrX, chrY, chrM.\n",
    "    Works for both 'chr1' and '1' styles.\n",
    "    \"\"\"\n",
    "    c = str(c)\n",
    "    c2 = c.replace(\"chr\", \"\")\n",
    "    if c2.isdigit():\n",
    "        return (0, int(c2))\n",
    "    if c2 == \"X\":\n",
    "        return (1, 23)\n",
    "    if c2 == \"Y\":\n",
    "        return (1, 24)\n",
    "    if c2 in (\"M\", \"MT\"):\n",
    "        return (2, 25)\n",
    "    return (3, c2)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) Load lncRNAs without positions\n",
    "# =========================\n",
    "df_no_pos = pd.read_csv(no_pos_file)\n",
    "no_pos_ids = set(df_no_pos['identifier'].astype(str))\n",
    "\n",
    "print(f\"[Info] Loaded {len(no_pos_ids)} lncRNAs without genomic positions from {no_pos_file}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Load BED\n",
    "# =========================\n",
    "df_bed = pd.read_csv(\n",
    "    bed_file, sep=\"\\t\", header=None,\n",
    "    names=[\"chr\", \"start\", \"end\", \"identifier\", \"score\", \"strand\"]\n",
    ")\n",
    "\n",
    "# Index by identifier for quick lookup\n",
    "bed_index = df_bed.set_index(\"identifier\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Load overlap pairs\n",
    "# =========================\n",
    "merge_pairs = pd.read_csv(overlap_file, sep=r\"\\s+\", header=None, names=[\"A\", \"B\"])\n",
    "merge_pairs = merge_pairs[merge_pairs[\"A\"] != merge_pairs[\"B\"]].copy()  # remove self-pairs\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Union-Find to group overlaps\n",
    "# =========================\n",
    "parent = {}\n",
    "\n",
    "def find(x):\n",
    "    parent.setdefault(x, x)\n",
    "    if parent[x] != x:\n",
    "        parent[x] = find(parent[x])\n",
    "    return parent[x]\n",
    "\n",
    "def union(x, y):\n",
    "    rx, ry = find(x), find(y)\n",
    "    if rx != ry:\n",
    "        parent[ry] = rx\n",
    "\n",
    "# Union all pairs (AB/BA redundancy does not affect final groups)\n",
    "for a, b in zip(merge_pairs[\"A\"], merge_pairs[\"B\"]):\n",
    "    union(a, b)\n",
    "\n",
    "# Build groups\n",
    "groups = defaultdict(set)\n",
    "all_ids_in_pairs = set(merge_pairs[\"A\"]).union(set(merge_pairs[\"B\"]))\n",
    "for gid in all_ids_in_pairs:\n",
    "    groups[find(gid)].add(gid)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Build clusters using union coordinates\n",
    "# =========================\n",
    "cluster_candidates = []  # each item: dict with chr/start/end/strand and member list\n",
    "\n",
    "for group in groups.values():\n",
    "    # Keep only members existing in BED (no_pos_ids will naturally be excluded)\n",
    "    members = [m for m in group if m in bed_index.index]\n",
    "    if len(members) == 0:\n",
    "        continue\n",
    "\n",
    "    group_df = bed_index.loc[members].copy()\n",
    "\n",
    "    # Union range\n",
    "    u_chr = group_df[\"chr\"].iloc[0]\n",
    "    u_strand = group_df[\"strand\"].iloc[0]\n",
    "    u_start = int(group_df[\"start\"].min())\n",
    "    u_end = int(group_df[\"end\"].max())\n",
    "\n",
    "    # Consistency check (should be consistent because bedtools used -s)\n",
    "    if len(set(group_df[\"chr\"])) != 1 or len(set(group_df[\"strand\"])) != 1:\n",
    "        print(f\"[Warning] Inconsistent chr/strand in group: {members}\")\n",
    "\n",
    "    members_sorted = sorted(members)\n",
    "\n",
    "    cluster_candidates.append({\n",
    "        \"chr\": u_chr,\n",
    "        \"start\": u_start,\n",
    "        \"end\": u_end,\n",
    "        \"strand\": u_strand,\n",
    "        \"members\": members_sorted\n",
    "    })\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Add singleton genes as clusters (not in any overlap group)\n",
    "# =========================\n",
    "merged_members = set().union(*[set(v) for v in groups.values()]) if groups else set()\n",
    "all_ids = set(df_bed[\"identifier\"])\n",
    "singleton_ids = all_ids - merged_members\n",
    "\n",
    "singleton_ids_sorted = sorted(\n",
    "    list(singleton_ids),\n",
    "    key=lambda x: (\n",
    "        chr_sort_key(bed_index.loc[x, \"chr\"]),\n",
    "        int(bed_index.loc[x, \"start\"]),\n",
    "        int(bed_index.loc[x, \"end\"]),\n",
    "        str(bed_index.loc[x, \"strand\"]),\n",
    "        x\n",
    "    )\n",
    ")\n",
    "\n",
    "for sid in singleton_ids_sorted:\n",
    "    row = bed_index.loc[sid]\n",
    "    cluster_candidates.append({\n",
    "        \"chr\": row[\"chr\"],\n",
    "        \"start\": int(row[\"start\"]),\n",
    "        \"end\": int(row[\"end\"]),\n",
    "        \"strand\": row[\"strand\"],\n",
    "        \"members\": [sid]\n",
    "    })\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) Assign incremental lncRNA_id (stable ordering)\n",
    "# =========================\n",
    "cluster_candidates_sorted = sorted(\n",
    "    cluster_candidates,\n",
    "    key=lambda x: (\n",
    "        chr_sort_key(x[\"chr\"]),\n",
    "        x[\"start\"],\n",
    "        x[\"end\"],\n",
    "        x[\"strand\"],\n",
    "        \";\".join(x[\"members\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "cluster_rows = []         \n",
    "mapping_long_rows = []    \n",
    "old_to_new = {}           \n",
    "\n",
    "for i, c in enumerate(cluster_candidates_sorted, start=1):\n",
    "    lncRNA_id = f\"l{i:06d}\"\n",
    "\n",
    "    # Record BED row\n",
    "    cluster_rows.append({\n",
    "        \"chr\": c[\"chr\"],\n",
    "        \"start\": c[\"start\"],\n",
    "        \"end\": c[\"end\"],\n",
    "        \"lncRNA_id\": lncRNA_id,\n",
    "        \"score\": 0,\n",
    "        \"strand\": c[\"strand\"]\n",
    "    })\n",
    "\n",
    "    # Record long mapping rows and dictionary mapping\n",
    "    for m in c[\"members\"]:\n",
    "        mapping_long_rows.append({\"lncRNA_id\": lncRNA_id, \"member_id\": m})\n",
    "        old_to_new[m] = lncRNA_id\n",
    "\n",
    "df_cluster_bed = pd.DataFrame(cluster_rows)\n",
    "df_mapping_long = pd.DataFrame(mapping_long_rows)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) Save BED6 and mapping table\n",
    "# =========================\n",
    "df_cluster_bed = df_cluster_bed.sort_values(\n",
    "    by=[\"chr\", \"start\", \"end\", \"strand\", \"lncRNA_id\"],\n",
    "    key=lambda col: col.map(chr_sort_key) if col.name == \"chr\" else col\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_mapping_long = df_mapping_long.sort_values([\"lncRNA_id\", \"member_id\"]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_cluster_bed[[\"chr\", \"start\", \"end\", \"lncRNA_id\", \"score\", \"strand\"]].to_csv(\n",
    "    out_bed, sep=\"\\t\", header=False, index=False\n",
    ")\n",
    "\n",
    "df_mapping_long.to_csv(out_mapping, index=False)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8) Update LPI: remove no-pos lncRNAs and map identifiers -> lncRNA_id\n",
    "# =========================\n",
    "df_lpi = pd.read_csv(lpi_file)\n",
    "\n",
    "lnc_col = df_lpi.columns[0]\n",
    "prot_col = df_lpi.columns[1]\n",
    "\n",
    "# Step 8.1: remove interactions involving no-pos lncRNAs BEFORE mapping\n",
    "df_lpi = df_lpi[~df_lpi[lnc_col].astype(str).isin(no_pos_ids)].copy()\n",
    "\n",
    "# Step 8.2: map lncRNA identifier to new lncRNA_id\n",
    "df_lpi[lnc_col] = df_lpi[lnc_col].map(lambda x: old_to_new.get(x, x))\n",
    "\n",
    "# Step 8.3: remove any interactions that still cannot be mapped (optional)\n",
    "# If you only want rows where lncRNA_id is a valid cluster id:\n",
    "valid_cluster_ids = set(df_cluster_bed[\"lncRNA_id\"])\n",
    "df_lpi = df_lpi[df_lpi[lnc_col].isin(valid_cluster_ids)].copy()\n",
    "\n",
    "# Step 8.4: deduplicate\n",
    "df_lpi = df_lpi.drop_duplicates(subset=[lnc_col, prot_col]).reset_index(drop=True)\n",
    "\n",
    "df_lpi.columns=['lncRNA_id','protein']\n",
    "df_lpi.to_csv(out_lpi, index=False)\n",
    "\n",
    "\n",
    "print(\"✅ Done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
