{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune layer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished structure: (32, 32)\n",
      "Finished structure: (64, 32)\n",
      "Finished structure: (64, 64)\n",
      "Finished structure: (128, 32)\n",
      "Finished structure: (128, 64)\n",
      "Finished structure: (128, 128)\n",
      "Finished structure: (256, 32)\n",
      "Finished structure: (256, 64)\n",
      "Finished structure: (256, 128)\n",
      "Finished structure: (256, 256)\n",
      "All configurations completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Change the following variables according to your needs\n",
    "species = 'mouse'\n",
    "tissue = 'heart'\n",
    "\n",
    "# -------------------- Load Data --------------------\n",
    "esslnc_path = f'../../data/benchmark/{species}/ess_lnc.csv'  \n",
    "nonesslnc_path = f'../../data/benchmark/{species}/noness_lnc.csv'  \n",
    "lncRNA_path = f'../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv'\n",
    "\n",
    "lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)\n",
    "esslnc = pd.read_csv(esslnc_path)\n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc['lncRNA_id'])\n",
    "nonesslnc_id = set(nonesslnc['lncRNA_id'])\n",
    "\n",
    "lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "X_positive = lnc_ess.to_numpy()\n",
    "X_negative = lnc_noness.to_numpy()\n",
    "ids_positive = np.array(lnc_ess.index)\n",
    "ids_negative = np.array(lnc_noness.index)\n",
    "\n",
    "X_all = np.vstack((X_positive, X_negative))\n",
    "y_all = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "ids_all = np.hstack((ids_positive, ids_negative))\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "hidden_layer_sizes = [32,64,128,256]  \n",
    "alpha = 1e-3\n",
    "learning_rate = 0.01\n",
    "input_dim = X_all.shape[1]\n",
    "\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "# -------------------- Grid Search --------------------\n",
    "for i in hidden_layer_sizes:\n",
    "    for j in hidden_layer_sizes:\n",
    "        if j > i:\n",
    "            continue\n",
    "        all_true_labels = []\n",
    "        all_pred_labels = []\n",
    "        all_pred_probs = []\n",
    "        # Prepare DataFrame to save experimental records\n",
    "        experiment_records = pd.DataFrame()\n",
    "\n",
    "        if species == 'mouse':\n",
    "            cv = LeaveOneOut() \n",
    "        else:\n",
    "            cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(cv.split(X_all)):\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "            ids_train, ids_test = ids_all[train_index], ids_all[test_index]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Instantiate custom MLP classifier\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=(i, j),\n",
    "                activation='relu',\n",
    "                alpha=1e-3,\n",
    "                learning_rate_init=0.01,\n",
    "                max_iter=200,\n",
    "                random_state=42\n",
    "            )\n",
    "            mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "            prob = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "            pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "            all_true_labels.extend(y_test.tolist())\n",
    "            all_pred_labels.extend(pred.tolist())\n",
    "            all_pred_probs.extend(prob.tolist())\n",
    "\n",
    "        # -------------------- Metrics --------------------\n",
    "        tn, fp, fn, tp = confusion_matrix(all_true_labels, all_pred_labels).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "        mcc = matthews_corrcoef(all_true_labels, all_pred_labels)\n",
    "\n",
    "        # Compute ROC curve and PR curve data\n",
    "        fpr, tpr, _ = roc_curve(all_true_labels, all_pred_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(all_true_labels, all_pred_probs)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        metrics = {\n",
    "            'layer_size_1': i,\n",
    "            'layer_size_2': j,\n",
    "            \"Sensitivity\": round(sensitivity, 4),\n",
    "            \"Specificity\": round(specificity, 4),\n",
    "            \"PPV\": round(ppv, 4),\n",
    "            \"F1 Score\": round(f1, 4),\n",
    "            \"Accuracy\": round(accuracy, 4),\n",
    "            \"MCC\": round(mcc, 4),\n",
    "            \"ROC AUC\": round(roc_auc, 4),\n",
    "            \"PR AUC\": round(pr_auc, 4),\n",
    "        }\n",
    "\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([metrics])], ignore_index=True)\n",
    "        print(f\"Finished structure: ({i}, {j})\")\n",
    "\n",
    "# -------------------- Save Results --------------------\n",
    "metrics_df.to_csv(f'./performance/{species}/mlp_layersize_metrics.csv', index=False)\n",
    "print(\"All configurations completed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MLP for human heart...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, matthews_corrcoef, roc_curve,\n",
    "    auc, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "\n",
    "species = 'human'\n",
    "tissue = 'heart'\n",
    "\n",
    "print(f\"Running MLP for {species} {tissue}...\")\n",
    "\n",
    "# ---------------------- 1. Load Data ----------------------\n",
    "esslnc_path = f'../../data/benchmark/{species}/ess_lnc.csv'\n",
    "nonesslnc_path = f'../../data/benchmark/{species}/noness_lnc.csv'\n",
    "\n",
    "lncRNA_path = f'../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv'\n",
    "\n",
    "lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)\n",
    "esslnc = pd.read_csv(esslnc_path)\n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc['lncRNA_id'])\n",
    "nonesslnc_id = set(nonesslnc['lncRNA_id'])\n",
    "\n",
    "lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "X_pos = lnc_ess.to_numpy()\n",
    "X_neg = lnc_noness.to_numpy()\n",
    "y_pos = np.ones(len(X_pos))\n",
    "y_neg = np.zeros(len(X_neg))\n",
    "\n",
    "X_all = np.vstack([X_pos, X_neg])\n",
    "y_all = np.hstack([y_pos, y_neg])\n",
    "ids_all = np.hstack([lnc_ess.index, lnc_noness.index])\n",
    "\n",
    "# ---------------------- 2. Init Containers ----------------------\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "all_pred_probs = []\n",
    "experiment_records = pd.DataFrame()\n",
    "roc_data, pr_data = [], []\n",
    "\n",
    "# ---------------------- 3. Cross-validation ----------------------\n",
    "# Initialize cross-validation\n",
    "if species == 'mouse':\n",
    "    cv = LeaveOneOut() \n",
    "    layer_size = (256,32)\n",
    "else:\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    layer_size = (128,64)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_all)):\n",
    "    X_train, X_test = X_all[train_idx], X_all[test_idx]\n",
    "    y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "    ids_train, ids_test = ids_all[train_idx], ids_all[test_idx]\n",
    "\n",
    "    # Normalize using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=layer_size,\n",
    "        activation='relu',\n",
    "        alpha=1e-3,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=200,\n",
    "        random_state=42\n",
    "    )\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    prob = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "    pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "    all_true_labels.extend(y_test.tolist())\n",
    "    all_pred_labels.extend(pred.tolist())\n",
    "    all_pred_probs.extend(prob.tolist())\n",
    "\n",
    "# ---------------------- 4. Evaluate ----------------------\n",
    "tn, fp, fn, tp = confusion_matrix(all_true_labels, all_pred_labels).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "mcc = matthews_corrcoef(all_true_labels, all_pred_labels)\n",
    "\n",
    "# ---------------------- 5. Save Results ----------------------\n",
    "# ROC & PR curve\n",
    "fpr, tpr, _ = roc_curve(all_true_labels, all_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_data.append(pd.DataFrame({'FPR': fpr, 'TPR': tpr}))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(all_true_labels, all_pred_probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "pr_data.append(pd.DataFrame({'Recall': recall, 'Precision': precision}))\n",
    "roc_data[0].to_csv(f'./performance/{species}/curve/roc_curve_{tissue}.csv', index=False)\n",
    "pr_data[0].to_csv(f'./performance/{species}/curve/pr_curve_{tissue}.csv', index=False)\n",
    "\n",
    "metrics_row = {\n",
    "    'Model': 'MLP',\n",
    "    'Cell_Line': f'{tissue}',\n",
    "    'Sensitivity': round(sensitivity,4),\n",
    "    'Specificity': round(specificity,4),\n",
    "    'PPV': round(ppv,4),\n",
    "    'F1 Score': round(f1,4),\n",
    "    'Accuracy': round(accuracy,4),\n",
    "    'MCC': round(mcc,4),\n",
    "    'ROC AUC': round(roc_auc,4),\n",
    "    'PR AUC': round(pr_auc,4)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_row])\n",
    "\n",
    "metrics_output_path = f'./performance/{species}/mlp_{tissue}_summary.csv'\n",
    "os.makedirs(os.path.dirname(metrics_output_path), exist_ok=True)\n",
    "if os.path.exists(metrics_output_path):\n",
    "    metrics_df.to_csv(metrics_output_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    metrics_df.to_csv(metrics_output_path, mode='w', header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "species = 'human'\n",
    "tissue = 'stomach'\n",
    "\n",
    "if species == 'mouse':\n",
    "\tlayer_size = (256,32)\n",
    "else:\n",
    "\tlayer_size = (128, 64)\n",
    "# ---------------------- 1. Load Data ----------------------\n",
    "\n",
    "# File paths\n",
    "esslnc_path = f'../../data/benchmark/{species}/ess_lnc.csv'\n",
    "nonesslnc_path = f'../../data/benchmark/{species}/noness_lnc.csv'\n",
    "\n",
    "esslnc = pd.read_csv(esslnc_path)  \n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc['lncRNA_id'])\n",
    "nonesslnc_id = set(nonesslnc['lncRNA_id'])\n",
    "\n",
    "all_samples_path = f'../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv'\n",
    "all_lnc = pd.read_csv(all_samples_path, index_col=0, header=None)\n",
    "\n",
    "lnc_ess = all_lnc[all_lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = all_lnc[all_lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "# Prepare training data\n",
    "X_positive = lnc_ess.values\n",
    "X_negative = lnc_noness.values\n",
    "\n",
    "X_train = np.vstack((X_positive, X_negative))\n",
    "y_train = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "\n",
    "# Split train/test set for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=layer_size,\n",
    "    activation='relu',\n",
    "    alpha=1e-3,\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on all data\n",
    "X_all = all_lnc.values\n",
    "ids_all = all_lnc.index\n",
    "\n",
    "X_all_scaled = scaler.transform(X_all)\n",
    "\n",
    "scores = mlp.predict_proba(X_all_scaled)[:,1] \n",
    "predictions = mlp.predict(X_all_scaled).astype(int)  # Convert predictions to int\n",
    "\n",
    "# Generate results DataFrame\n",
    "results_df = pd.DataFrame({'lncRNA_id': ids_all, 'Score': scores, 'Pre_Label': predictions})\n",
    "\n",
    "# Save results to CSV file\n",
    "results_df.to_csv(f'../../results/{species}/MLP_predictions_{tissue}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
