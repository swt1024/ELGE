{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fold details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "# Change the following variables according to your needs\n",
    "species = \"human\"\n",
    "tissue = \"heart\"\n",
    "\n",
    "esslnc_path = f\"../../data/benchmark/{species}/ess_lnc.csv\"\n",
    "nonesslnc_path = f\"../../data/benchmark/{species}/noness_lnc.csv\"\n",
    "\n",
    "esslnc = pd.read_csv(esslnc_path)\n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc[\"lncRNA_id\"])\n",
    "nonesslnc_id = set(nonesslnc[\"lncRNA_id\"])\n",
    "\n",
    "# File paths\n",
    "lncRNA_path = f\"../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv\"\n",
    "lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)\n",
    "\n",
    "lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "# Prepare data arrays\n",
    "X_positive = lnc_ess.values\n",
    "X_negative = lnc_noness.values\n",
    "ids_positive = lnc_ess.index\n",
    "ids_negative = lnc_noness.index\n",
    "\n",
    "# Combine datasets\n",
    "X_all = np.vstack((X_positive, X_negative))\n",
    "y_all = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "ids_all = np.hstack((ids_positive, ids_negative))\n",
    "\n",
    "\n",
    "# Choose CV strategy\n",
    "if species == 'mouse':\n",
    "    cv = LeaveOneOut() \n",
    "else:\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold_records = pd.DataFrame()\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(cv.split(X_all)):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    ids_train, ids_test = ids_all[train_index], ids_all[test_index]\n",
    "\n",
    "    fold_data = {\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Train_IDs\": [list(ids_train)],\n",
    "        \"Train_Labels\": [list(y_train)],\n",
    "        \"Test_IDs\": [list(ids_test)],\n",
    "        \"Test_Labels\": [list(y_test)],\n",
    "    }\n",
    "    fold_df = pd.DataFrame(fold_data)\n",
    "    fold_records = pd.concat([fold_records, fold_df], ignore_index=True)\n",
    "\n",
    "fold_records.to_csv(\n",
    "    f\"../fold_details/{species}_fold_details.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning layer size for HinSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done!\n",
      "Metrics saved to: ./performance/mouse/hinsage_layersize_heart_metrics_RBF_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "layer_size_1 = [16, 32, 64]\n",
    "layer_size_2 = [32, 64, 128, 256]\n",
    "\n",
    "# Change the following variables according to your needs\n",
    "species = \"mouse\"\n",
    "tissue = \"heart\"\n",
    "\n",
    "esslnc_path = f\"../../data/benchmark/{species}/ess_lnc.csv\"\n",
    "nonesslnc_path = f\"../../data/benchmark/{species}/noness_lnc.csv\"\n",
    "\n",
    "esslnc = pd.read_csv(esslnc_path)\n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc[\"lncRNA_id\"])\n",
    "nonesslnc_id = set(nonesslnc[\"lncRNA_id\"])\n",
    "\n",
    "metrics_df = pd.DataFrame()  # DataFrame to store metrics for each configuration\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(f\"./performance/{species}\", exist_ok=True)\n",
    "\n",
    "for i in layer_size_1:\n",
    "    for j in layer_size_2:\n",
    "\n",
    "        # File paths\n",
    "        lncRNA_path = f\"../../HinSAGE/{species}/layer_size/lncRNA_embeddings_{tissue}_{i}_{j}.csv\"\n",
    "        lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)\n",
    "\n",
    "        lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "        lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "        # Prepare data arrays\n",
    "        X_positive = lnc_ess.values\n",
    "        X_negative = lnc_noness.values\n",
    "        ids_positive = lnc_ess.index\n",
    "        ids_negative = lnc_noness.index\n",
    "\n",
    "        # Combine datasets\n",
    "        X_all = np.vstack((X_positive, X_negative))\n",
    "        y_all = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "        ids_all = np.hstack((ids_positive, ids_negative))\n",
    "\n",
    "        # Initialize lists to store all true labels and decision scores\n",
    "        all_true_labels = []\n",
    "        all_decision_scores = []\n",
    "\n",
    "        # Choose CV strategy\n",
    "        if species == 'mouse':\n",
    "            cv = LeaveOneOut() \n",
    "        else:\n",
    "            cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(cv.split(X_all)):\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "            ids_train, ids_test = ids_all[train_index], ids_all[test_index]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # ✅ RBF-SVM with fixed parameters: C=10, gamma=\"scale\"\n",
    "            svm = SVC(kernel=\"rbf\", C=10, gamma=\"scale\")\n",
    "            svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "            decision_scores = svm.decision_function(X_test_scaled)\n",
    "            predictions = (decision_scores >= 0).astype(int)\n",
    "\n",
    "            all_true_labels.extend(y_test)\n",
    "            all_decision_scores.extend(decision_scores)\n",
    "\n",
    "        # Convert lists to arrays\n",
    "        all_true_labels = np.array(all_true_labels)\n",
    "        all_decision_scores = np.array(all_decision_scores)\n",
    "\n",
    "        # Confusion matrix using threshold=0\n",
    "        tn, fp, fn, tp = confusion_matrix(all_true_labels, (all_decision_scores >= 0).astype(int)).ravel()\n",
    "\n",
    "        # Avoid division-by-zero\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "        mcc = matthews_corrcoef(all_true_labels, (all_decision_scores >= 0).astype(int))\n",
    "\n",
    "        # ROC curve & AUC\n",
    "        fpr, tpr, _ = roc_curve(all_true_labels, all_decision_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Precision-Recall curve & AUC\n",
    "        precision, recall, _ = precision_recall_curve(all_true_labels, all_decision_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        metrics = {\n",
    "            \"layer_size_1\": i,\n",
    "            \"layer_size_2\": j,\n",
    "            \"Sensitivity\": round(sensitivity, 4),\n",
    "            \"Specificity\": round(specificity, 4),\n",
    "            \"PPV\": round(ppv, 4),\n",
    "            \"F1 Score\": round(f1_score, 4),\n",
    "            \"Accuracy\": round(accuracy, 4),\n",
    "            \"MCC\": round(mcc, 4),\n",
    "            \"ROC AUC\": round(roc_auc, 4),\n",
    "            \"PR AUC\": round(pr_auc, 4),\n",
    "        }\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Save metrics DataFrame\n",
    "metrics_df.to_csv(f\"./performance/{species}/hinsage_layersize_{tissue}_metrics_RBF_fixed.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done!\")\n",
    "print(f\"Metrics saved to: ./performance/{species}/hinsage_layersize_{tissue}_metrics_RBF_fixed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning samples numbers for HinSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done!\n",
      "Metrics saved to: ./performance/mouse/hinsage_samplesnum_heart_metrics_RBF_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut \n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "samples_num_1=[5,10,15,20]\n",
    "samples_num_2=[10,15,20,25]\n",
    "\n",
    "# Change the following variables according to your needs\n",
    "species = 'mouse'\n",
    "tissue = 'heart'\n",
    "\n",
    "esslnc_path = f'../../data/benchmark/{species}/ess_lnc.csv'  \n",
    "nonesslnc_path = f'../../data/benchmark/{species}/noness_lnc.csv'  \n",
    "\n",
    "esslnc = pd.read_csv(esslnc_path)  \n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc['lncRNA_id'])\n",
    "nonesslnc_id = set(nonesslnc['lncRNA_id'])\n",
    "\n",
    "metrics_df = pd.DataFrame()  # DataFrame to store metrics for each configuration\n",
    "\n",
    "for i in samples_num_1:\n",
    "    for j in samples_num_2:\n",
    "\n",
    "        # File paths\n",
    "        lncRNA_path = f'../../HinSAGE/{species}/samples_num/lncRNA_embeddings_heart_{i}_{j}.csv'\n",
    "        lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)  \n",
    "\n",
    "        lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "        lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "        # Prepare data arrays\n",
    "        X_positive = lnc_ess.values\n",
    "        X_negative = lnc_noness.values\n",
    "        ids_positive = lnc_ess.index\n",
    "        ids_negative = lnc_noness.index\n",
    "\n",
    "        # Combine datasets\n",
    "        X_all = np.vstack((X_positive, X_negative))\n",
    "        y_all = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "        ids_all = np.hstack((ids_positive, ids_negative))\n",
    "\n",
    "        # Initialize lists to store all true labels and decision scores\n",
    "        all_true_labels = []\n",
    "        all_decision_scores = []\n",
    "\n",
    "        if species == 'mouse':\n",
    "            cv = LeaveOneOut() \n",
    "        else:\n",
    "            cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(cv.split(X_all)):\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "            ids_train, ids_test = ids_all[train_index], ids_all[test_index]\n",
    "\n",
    "            # Apply MinMaxScaler\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # ✅ RBF-SVM with fixed parameters: C=10, gamma=\"scale\"\n",
    "            svm = SVC(kernel=\"rbf\", C=10, gamma=\"scale\")\n",
    "            svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "            decision_scores = svm.decision_function(X_test_scaled)\n",
    "            predictions = (decision_scores >= 0).astype(int)\n",
    "\n",
    "            all_true_labels.extend(y_test)\n",
    "            all_decision_scores.extend(decision_scores)\n",
    "\n",
    "        # Convert lists to arrays for performance evaluation\n",
    "        all_true_labels = np.array(all_true_labels)\n",
    "        all_decision_scores = np.array(all_decision_scores)\n",
    "\n",
    "        # Compute confusion matrix using threshold at 0\n",
    "        tn, fp, fn, tp = confusion_matrix(all_true_labels, (all_decision_scores >= 0).astype(int)).ravel()\n",
    "\n",
    "        # Compute performance metrics\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "        mcc = matthews_corrcoef(all_true_labels, (all_decision_scores >= 0).astype(int))\n",
    "\n",
    "        # Compute and save ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(all_true_labels, all_decision_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Compute and save Precision-Recall curve data\n",
    "        precision, recall, _ = precision_recall_curve(all_true_labels, all_decision_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        metrics = {\n",
    "            \"layer_size_1\": i,\n",
    "            \"layer_size_2\": j,\n",
    "            \"Sensitivity\": round(sensitivity, 4),\n",
    "            \"Specificity\": round(specificity, 4),\n",
    "            \"PPV\": round(ppv, 4),\n",
    "            \"F1 Score\": round(f1_score, 4),\n",
    "            \"Accuracy\": round(accuracy, 4),\n",
    "            \"MCC\": round(mcc, 4),\n",
    "            \"ROC AUC\": round(roc_auc, 4),\n",
    "            \"PR AUC\": round(pr_auc, 4),\n",
    "        }\n",
    "        new_row = pd.DataFrame([metrics])\n",
    "        metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "# Save metrics DataFrame to CSV\n",
    "metrics_df.to_csv(f\"./performance/{species}/hinsage_samplesnum_{tissue}_metrics_RBF_fixed.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done!\")\n",
    "print(f\"Metrics saved to: ./performance/{species}/hinsage_samplesnum_{tissue}_metrics_RBF_fixed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune C and gamma for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Change the following variables according to your needs\n",
    "species = \"human\"\n",
    "tissue = \"heart\"\n",
    "\n",
    "esslnc_path = f\"../../data/benchmark/{species}/ess_lnc.csv\"\n",
    "nonesslnc_path = f\"../../data/benchmark/{species}/noness_lnc.csv\"\n",
    "lncRNA_path = f\"../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv\"\n",
    "\n",
    "# Output directory\n",
    "out_dir = f\"./performance/{species}\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Read data\n",
    "lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)\n",
    "esslnc = pd.read_csv(esslnc_path)\n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc[\"lncRNA_id\"])\n",
    "nonesslnc_id = set(nonesslnc[\"lncRNA_id\"])\n",
    "\n",
    "lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "# Prepare data arrays\n",
    "X_positive = lnc_ess.values\n",
    "X_negative = lnc_noness.values\n",
    "ids_positive = lnc_ess.index\n",
    "ids_negative = lnc_noness.index\n",
    "\n",
    "# Combine datasets\n",
    "X_all = np.vstack((X_positive, X_negative))\n",
    "y_all = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "ids_all = np.hstack((ids_positive, ids_negative))\n",
    "\n",
    "# Define grid search space for RBF-SVM\n",
    "C_values = [1, 10, 100]\n",
    "gamma_values = [0.1, 0.01, 0.001]\n",
    "\n",
    "# Prepare to store results\n",
    "results = []\n",
    "\n",
    "# Initialize CV\n",
    "if species == \"mouse\":\n",
    "    cv = LeaveOneOut()\n",
    "else:\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search over (C, gamma)\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        all_true_labels = []\n",
    "        all_decision_scores = []\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(cv.split(X_all)):\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "\n",
    "            # ✅ StandardScaler \n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # ✅ RBF-SVM\n",
    "            svm = SVC(kernel=\"rbf\", C=C, gamma=gamma)\n",
    "            svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "            decision_scores = svm.decision_function(X_test_scaled)\n",
    "\n",
    "            all_true_labels.extend(y_test)\n",
    "            all_decision_scores.extend(decision_scores)\n",
    "\n",
    "        # Convert lists to arrays\n",
    "        all_true_labels = np.array(all_true_labels)\n",
    "        all_decision_scores = np.array(all_decision_scores)\n",
    "        y_pred = (all_decision_scores >= 0).astype(int)\n",
    "\n",
    "        # Confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(all_true_labels, y_pred).ravel()\n",
    "\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "        mcc = matthews_corrcoef(all_true_labels, y_pred)\n",
    "\n",
    "        # ROC AUC\n",
    "        fpr, tpr, _ = roc_curve(all_true_labels, all_decision_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # PR AUC\n",
    "        precision, recall, _ = precision_recall_curve(all_true_labels, all_decision_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        results.append({\n",
    "            \"C\": C,\n",
    "            \"gamma\": gamma,\n",
    "            \"Sensitivity\": round(sensitivity, 4),\n",
    "            \"Specificity\": round(specificity, 4),\n",
    "            \"PPV\": round(ppv, 4),\n",
    "            \"F1 Score\": round(f1_score, 4),\n",
    "            \"Accuracy\": round(accuracy, 4),\n",
    "            \"MCC\": round(mcc, 4),\n",
    "            \"ROC AUC\": round(roc_auc, 4),\n",
    "            \"PR AUC\": round(pr_auc, 4),\n",
    "        })\n",
    "\n",
    "# Save all results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"PPV\", ascending=False)\n",
    "out_file = f\"{out_dir}/rbf_svm_grid.csv\"\n",
    "results_df.to_csv(out_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut \n",
    "import os\n",
    "\n",
    "species = 'human'\n",
    "tissue = 'stomach'\n",
    "\n",
    "# File paths\n",
    "esslnc_path = f'../../data/benchmark/{species}/ess_lnc.csv'\n",
    "nonesslnc_path = f'../../data/benchmark/{species}/noness_lnc.csv'\n",
    "\n",
    "lncRNA_path = f'../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv'\n",
    "\n",
    "lnc = pd.read_csv(lncRNA_path, index_col=0, header=None)  \n",
    "\n",
    "esslnc = pd.read_csv(esslnc_path)  \n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc['lncRNA_id'])\n",
    "nonesslnc_id = set(nonesslnc['lncRNA_id'])\n",
    "\n",
    "lnc_ess = lnc[lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = lnc[lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "# Prepare data arrays\n",
    "X_positive = lnc_ess.values\n",
    "X_negative = lnc_noness.values\n",
    "ids_positive = lnc_ess.index\n",
    "ids_negative = lnc_noness.index\n",
    "\n",
    "# Combine datasets\n",
    "X_all = np.vstack((X_positive, X_negative))\n",
    "y_all = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "ids_all = np.hstack((ids_positive, ids_negative))\n",
    "\n",
    "# Initialize cross-validation\n",
    "if species == 'mouse':\n",
    "    cv = LeaveOneOut() \n",
    "    C = 10\n",
    "    gamma = 0.01\n",
    "else:\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    C = 100\n",
    "    gamma = 0.001\n",
    "\n",
    "# Prepare DataFrame to save roc and pr\n",
    "roc_data = []\n",
    "pr_data = []\n",
    "\n",
    "# Initialize lists to store all true labels and decision scores\n",
    "all_true_labels = []\n",
    "all_decision_scores = []\n",
    "\n",
    "# cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(cv.split(X_all)):\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    ids_train, ids_test = ids_all[train_index], ids_all[test_index]\n",
    "    \n",
    "    # ✅ StandardScaler \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # ✅ RBF-SVM\n",
    "    svm = SVC(kernel=\"rbf\", C=C, gamma=gamma)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "    decision_scores = svm.decision_function(X_test_scaled)\n",
    "    predictions = (decision_scores >= 0).astype(int)\n",
    "    \n",
    "    all_true_labels.extend(y_test)\n",
    "    all_decision_scores.extend(decision_scores)\n",
    "\n",
    "# Convert lists to arrays for performance evaluation\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "all_decision_scores = np.array(all_decision_scores)\n",
    "\n",
    "# Compute confusion matrix using threshold at 0\n",
    "tn, fp, fn, tp = confusion_matrix(all_true_labels, (all_decision_scores >= 0).astype(int)).ravel()\n",
    "\n",
    "# Compute performance metrics\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "mcc = matthews_corrcoef(all_true_labels, (all_decision_scores >= 0).astype(int))\n",
    "\n",
    "# Compute and save ROC curve data\n",
    "fpr, tpr, _ = roc_curve(all_true_labels, all_decision_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_data.append(pd.DataFrame({'FPR': fpr, 'TPR': tpr}))\n",
    "\n",
    "# Compute and save Precision-Recall curve data\n",
    "precision, recall, _ = precision_recall_curve(all_true_labels, all_decision_scores)\n",
    "pr_auc = auc(recall, precision)\n",
    "pr_data.append(pd.DataFrame({'Recall': recall, 'Precision': precision}))\n",
    "\n",
    "metrics_row = {\n",
    "    'Model': 'SVM',\n",
    "    'Tissue': f'{tissue}',\n",
    "    'Sensitivity': round(sensitivity,4),\n",
    "    'Specificity': round(specificity,4),\n",
    "    'PPV': round(ppv,4),\n",
    "    'F1 Score': round(f1_score,4),\n",
    "    'Accuracy': round(accuracy,4),\n",
    "    'MCC': round(mcc,4),\n",
    "    'ROC AUC': round(roc_auc,4),\n",
    "    'PR AUC': round(pr_auc,4)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_row])\n",
    "\n",
    "metrics_output_path = f'./performance/{species}/svm_{tissue}_summary.csv'\n",
    "os.makedirs(os.path.dirname(metrics_output_path), exist_ok=True)\n",
    "\n",
    "if os.path.exists(metrics_output_path):\n",
    "    metrics_df.to_csv(metrics_output_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    metrics_df.to_csv(metrics_output_path, mode='w', header=True, index=False)\n",
    "\n",
    "roc_data[0].to_csv(f'./performance/{species}/curve/roc_curve_{tissue}.csv', index=False)\n",
    "pr_data[0].to_csv(f'./performance/{species}/curve/pr_curve_{tissue}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "species = 'human'\n",
    "tissue = 'stomach'\n",
    "\n",
    "if species == 'mouse':\n",
    "\tC = 10\n",
    "\tgamma = 0.01\n",
    "else:\n",
    "\tC = 100\n",
    "\tgamma = 0.001\n",
    "\n",
    "# File paths\n",
    "esslnc_path = f'../../data/benchmark/{species}/ess_lnc.csv'\n",
    "nonesslnc_path = f'../../data/benchmark/{species}/noness_lnc.csv'\n",
    "\n",
    "esslnc = pd.read_csv(esslnc_path)  \n",
    "nonesslnc = pd.read_csv(nonesslnc_path)\n",
    "\n",
    "esslnc_id = set(esslnc['lncRNA_id'])\n",
    "nonesslnc_id = set(nonesslnc['lncRNA_id'])\n",
    "\n",
    "all_samples_path = f'../../HinSAGE/{species}/lncRNA_embeddings_{tissue}.csv'\n",
    "all_lnc = pd.read_csv(all_samples_path, index_col=0, header=None)\n",
    "\n",
    "lnc_ess = all_lnc[all_lnc.index.isin(esslnc_id)]\n",
    "lnc_noness = all_lnc[all_lnc.index.isin(nonesslnc_id)]\n",
    "\n",
    "# Prepare training data\n",
    "X_positive = lnc_ess.values\n",
    "X_negative = lnc_noness.values\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.vstack((X_positive, X_negative))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = np.hstack((np.ones(len(X_positive)), np.zeros(len(X_negative))))\n",
    "\n",
    "# Train SVM model\n",
    "svm = SVC(kernel=\"rbf\", C=C, gamma=gamma)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score and predict for all data\n",
    "X_all = all_lnc.values\n",
    "X_all_scaled = scaler.transform(X_all)\n",
    "ids_all = all_lnc.index\n",
    "\n",
    "scores = svm.decision_function(X_all_scaled)\n",
    "labels = np.where(scores > 0, 1, 0)\n",
    "\n",
    "# Generate results DataFrame\n",
    "results_df = pd.DataFrame({'lncRNA_id': ids_all, 'Score': scores, 'Pre_Label': labels})\n",
    "\n",
    "# Save results to CSV file\n",
    "results_df.to_csv(f'../../results/{species}/SVM_predictions_{tissue}.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
